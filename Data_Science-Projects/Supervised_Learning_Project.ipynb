{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Final Project\n",
    "## This project will be analyzing customer behavior at Beta Bank to determine if it can be predicted if a customer will end its membership at the bank. Classification models such as Logistic Regressions and Decision Tree Classifiers will be used. The critieria for a successful model is a model that computes a F1 Score of 0.59 or higher.\n",
    "\n",
    "## The steps in this project will be as follows: \n",
    "## 1. Loading the data, all necessary packages, and prepare the data for analysis\n",
    "## 2. Check the balance of classes and train different models without factoring class imbalance\n",
    "## 3. Improve the quality of the best model, use class balancing strategies\n",
    "## 4. Final test and analyze the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and start data preparation\n",
    "\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Detailed look at the data\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9945</td>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9957</td>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9965</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "30           31    15589475    Azikiwe          591     Spain  Female   39   \n",
       "48           49    15766205        Yin          550   Germany    Male   38   \n",
       "51           52    15768193  Trevisani          585   Germany    Male   36   \n",
       "53           54    15702298   Parkhill          655   Germany    Male   41   \n",
       "60           61    15651280     Hunter          742   Germany    Male   35   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9944       9945    15703923    Cameron          744   Germany    Male   41   \n",
       "9956       9957    15707861      Nucci          520    France  Female   46   \n",
       "9964       9965    15642785    Douglas          479    France    Male   34   \n",
       "9985       9986    15586914     Nepean          659    France    Male   36   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "30       NaN       0.00              3          1               0   \n",
       "48       NaN  103391.38              1          0               1   \n",
       "51       NaN  146050.97              2          0               0   \n",
       "53       NaN  125561.97              1          0               0   \n",
       "60       NaN  136857.00              1          0               0   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9944     NaN  190409.34              2          1               1   \n",
       "9956     NaN   85216.61              1          1               0   \n",
       "9964     NaN  117593.48              2          0               0   \n",
       "9985     NaN  123841.49              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "30          140469.38       1  \n",
       "48           90878.13       0  \n",
       "51           86424.57       0  \n",
       "53          164040.94       1  \n",
       "60           84509.57       0  \n",
       "...               ...     ...  \n",
       "9944        138361.48       0  \n",
       "9956        117369.52       1  \n",
       "9964        113308.29       0  \n",
       "9985         96833.00       0  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[909 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at all rows with missing data to identify any trends\n",
    "\n",
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "9995          771    France    Male   39     5.0       0.00              2   \n",
       "9996          516    France    Male   35    10.0   57369.61              1   \n",
       "9997          709    France  Female   36     7.0       0.00              1   \n",
       "9998          772   Germany    Male   42     3.0   75075.31              2   \n",
       "9999          792    France  Female   28     5.0  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling missing values with median of that column since it is only a small percent of the data\n",
    "# The median of the tenure column is 5.0 and the mean is around 4.99 so they are similar\n",
    "# Median was chose to avoid outliers greatly affecting the data\n",
    "\n",
    "data = data.fillna(data.median())\n",
    "#print(data['Tenure'].mean())\n",
    "data = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "data.info()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  float64\n",
      " 1   Age                10000 non-null  float64\n",
      " 2   Tenure             10000 non-null  float64\n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  float64\n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_Germany  10000 non-null  uint8  \n",
      " 10  Geography_Spain    10000 non-null  uint8  \n",
      " 11  Gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(6), int64(3), uint8(3)\n",
      "memory usage: 732.5 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.087768</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.326221  0.293517 -1.086246 -1.225848      -0.911583          1   \n",
       "1    -0.440036  0.198164 -1.448581  0.117350      -0.911583          0   \n",
       "2    -1.536794  0.293517  1.087768  1.333053       2.527057          1   \n",
       "3     0.501521  0.007457 -1.448581 -1.225848       0.807737          0   \n",
       "4     2.063884  0.388871 -1.086246  0.785728      -0.911583          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1         0.021886       1                  0   \n",
       "1               1         0.216534       0                  0   \n",
       "2               0         0.240687       1                  0   \n",
       "3               0        -0.108918       0                  0   \n",
       "4               1        -0.365276       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using One Hot Encode to prepare the data for a Logistic Regression. Also normalizing the numeric data using standard scaler\n",
    "\n",
    "data_ohe = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "features_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the numerical features\n",
    "data_ohe[features_to_scale] = scaler.fit_transform(data_ohe[features_to_scale])\n",
    "\n",
    "# Display the first few rows of the preprocessed dataset\n",
    "print(data_ohe.info())\n",
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of the target variable\n",
    "\n",
    "class_balance = data_ohe['Exited'].value_counts(normalize=True)\n",
    "print(class_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target column 'Exited' is imbalanced, with a majority of the class of '0' and a minority of '1'. This can affect the models because of the bias towards the majority class. Training the models without taking into account this class imbalance will result in models with skewed metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next section will be adjusting and tuning a Logistic Regression to get the best f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (6000, 11), (6000,)\n",
      "Validation set: (2000, 11), (2000,)\n",
      "Test set: (2000, 11), (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and validation sets for Logistic Regression\n",
    "\n",
    "#target = data_ohe['Exited']\n",
    "#features = data_ohe.drop(columns=['Exited']) \n",
    "#features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "#    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Splitting data into training, validation, and testing sets\n",
    "\n",
    "# Creating features list and target list\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop(columns=['Exited'])\n",
    "\n",
    "# Splitting into training (60%) and temporary (40%). Used random_state=12345 as shown in the sprint.\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "# Splitting the temporary set into validation (20%) and test (20%)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Verify the sizes of the splits following the traditional 3:1:1 split.\n",
    "print(f'Training set: {features_train.shape}, {target_train.shape}')\n",
    "print(f'Validation set: {features_valid.shape}, {target_valid.shape}')\n",
    "print(f'Test set: {features_test.shape}, {target_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.33108108108108103\n",
      "Confusion Matrix: [[1506   76]\n",
      " [ 320   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1582\n",
      "           1       0.56      0.23      0.33       418\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.69      0.59      0.61      2000\n",
      "weighted avg       0.77      0.80      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running a Logisitic Regression on data with no hyperparameters or class balancing to get a base f1 score\n",
    "\n",
    "log_model = LogisticRegression(random_state=12345)\n",
    "log_model.fit(features_train, target_train)\n",
    "predicted_log_valid = log_model.predict(features_valid)\n",
    "\n",
    "f1_log_valid = f1_score(target_valid, predicted_log_valid)\n",
    "print('F1 Score:', f1_log_valid)\n",
    "#print('Accuracy Score:', accuracy_score(target_valid, predicted_log_valid))\n",
    "print('Confusion Matrix:', confusion_matrix(target_valid, predicted_log_valid))\n",
    "print(classification_report(target_valid, predicted_log_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of a Logistic Regression with little data preparation, no hyperparameters besides random_state, results in an f1_score of 0.33 which means the model performs poorly. The ratio between precision and recall is around 0.33 most likely means the recall is low and the model cannot balance the two metrics. This is probably due to the fact that the data itself is imbalanced towards the column 'Exited' which is biased towards equaling 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7588057029137607\n"
     ]
    }
   ],
   "source": [
    "# Calculate roc_auc_score\n",
    "\n",
    "probabilities_valid = log_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A roc_auc_score of 0.7588 means that the model is fairly good at distinguishing between the negative and positive classes across all possible classification thresholds and is significantly better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4888507718696398\n",
      "Confusion Matrix: [[1119  463]\n",
      " [ 133  285]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding hyperparameter class_weight to balance the classes\n",
    "\n",
    "log_model = LogisticRegression(class_weight = 'balanced',random_state=12345)\n",
    "log_model.fit(features_train, target_train)\n",
    "predicted_log_valid = log_model.predict(features_valid)\n",
    "\n",
    "f1_log_valid = f1_score(target_valid, predicted_log_valid)\n",
    "print('F1 Score:', f1_log_valid)\n",
    "\n",
    "#print('Accuracy Score:', accuracy_score(target_valid, predicted_log_valid))\n",
    "\n",
    "print('Confusion Matrix:', confusion_matrix(target_valid, predicted_log_valid))\n",
    "print(classification_report(target_valid, predicted_log_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a class_weight= 'balanced' parameter increased the f1_score from 0.33 to 0.48885 which is better but not yet at the 0.59 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7636781011257023\n"
     ]
    }
   ],
   "source": [
    "# Calculate roc_auc_score\n",
    "\n",
    "probabilities_valid = log_model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roc_auc_score remained basically the same, suggesting the model still can distinguish positive and negative weight fairly accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part will be upsampling and downsampling the data to see if the balance of classes can be improved to also improve the f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample function to increase positive cases\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 unbalanced model: 0.33108108108108103\n",
      "Factor: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1582\n",
      "           1       0.56      0.23      0.33       418\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.69      0.59      0.61      2000\n",
      "weighted avg       0.77      0.80      0.77      2000\n",
      "\n",
      "roc_auc_score unbalanced model: 0.7588057029137607\n",
      "\n",
      "F1 balanced model: 0.4888507718696398\n",
      "Factor: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n",
      "roc_auc_score balanced model: 0.7636781011257023\n",
      "F1 unbalanced model: 0.46437346437346433\n",
      "Factor: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      1582\n",
      "           1       0.48      0.45      0.46       418\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.67      0.66      0.66      2000\n",
      "weighted avg       0.78      0.78      0.78      2000\n",
      "\n",
      "roc_auc_score unbalanced model: 0.761385563667818\n",
      "\n",
      "F1 balanced model: 0.4888507718696398\n",
      "Factor: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n",
      "roc_auc_score balanced model: 0.7636508810239597\n",
      "F1 unbalanced model: 0.5\n",
      "Factor: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1582\n",
      "           1       0.43      0.60      0.50       418\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.66      0.69      0.67      2000\n",
      "weighted avg       0.79      0.75      0.76      2000\n",
      "\n",
      "roc_auc_score unbalanced model: 0.7626709573612228\n",
      "\n",
      "F1 balanced model: 0.4888507718696398\n",
      "Factor: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n",
      "roc_auc_score balanced model: 0.7636478565682105\n",
      "F1 unbalanced model: 0.4888507718696398\n",
      "Factor: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n",
      "roc_auc_score unbalanced model: 0.7636160997828441\n",
      "\n",
      "F1 balanced model: 0.4888507718696398\n",
      "Factor: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n",
      "roc_auc_score balanced model: 0.7636297098337154\n",
      "F1 unbalanced model: 0.4847094801223242\n",
      "Factor: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75      1582\n",
      "           1       0.36      0.76      0.48       418\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.63      0.70      0.62      2000\n",
      "weighted avg       0.79      0.66      0.69      2000\n",
      "\n",
      "roc_auc_score unbalanced model: 0.7642391376671768\n",
      "\n",
      "F1 balanced model: 0.4888507718696398\n",
      "Factor: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79      1582\n",
      "           1       0.38      0.68      0.49       418\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.64      0.69      0.64      2000\n",
      "weighted avg       0.79      0.70      0.73      2000\n",
      "\n",
      "roc_auc_score balanced model: 0.7636266853779662\n",
      "Best f1_score: 0.5\n",
      "Best factor: 3\n"
     ]
    }
   ],
   "source": [
    "# Running Logistic Regression using upsampling. Showing f1_score, classification report, and roc_auc_score.\n",
    "\n",
    "best_factor = 0\n",
    "best_f1 = 0\n",
    "for i in range(1,6): # For loop to find the best integer for repeat parameter\n",
    "    features_upsampled, target_upsampled = upsample(features_train, target_train, i)\n",
    "    model_upsample = LogisticRegression( random_state=12345)\n",
    "    model_upsample.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid_upsample = model_upsample.predict(features_valid)\n",
    "    \n",
    "    f1 = f1_score(target_valid, predicted_valid_upsample)\n",
    "    if(f1 > best_f1): # if statement to save the best f1 score that will be calculated\n",
    "        best_f1 = f1\n",
    "        best_factor = i\n",
    "        \n",
    "    \n",
    "    print('F1 unbalanced model:', f1_score(target_valid, predicted_valid_upsample))\n",
    "    print('Factor:', i)\n",
    "    print(classification_report(target_valid, predicted_valid_upsample))\n",
    "\n",
    "    probabilities_valid = model_upsample.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('roc_auc_score unbalanced model:', roc_auc)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    model_upsample = LogisticRegression(class_weight= 'balanced', random_state=12345)\n",
    "    model_upsample.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid_upsample = model_upsample.predict(features_valid)\n",
    "    \n",
    "    f1 = f1_score(target_valid, predicted_valid_upsample)\n",
    "    if(f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        best_factor = i\n",
    "    \n",
    "    print('F1 balanced model:', f1_score(target_valid, predicted_valid_upsample))\n",
    "    print('Factor:', i )\n",
    "    print(classification_report(target_valid, predicted_valid_upsample))\n",
    "\n",
    "    probabilities_valid = model_upsample.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print('roc_auc_score balanced model:', roc_auc)\n",
    "print('Best f1_score:', best_f1)\n",
    "print('Best factor:', best_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous cell it is determined that a Logistic Regression with no class_weight parameter and a repeat value of 3 for the upsampling function gives the best f1_score of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1582\n",
      "           1       0.43      0.60      0.50       418\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.66      0.69      0.67      2000\n",
      "weighted avg       0.79      0.75      0.76      2000\n",
      "\n",
      "roc_auc_score: 0.7626709573612228\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with best parameters for upsampling\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 3)\n",
    "model_upsample = LogisticRegression( random_state=12345)\n",
    "model_upsample.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_valid_upsample = model_upsample.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid_upsample))\n",
    "print(classification_report(target_valid, predicted_valid_upsample))\n",
    "\n",
    "probabilities_valid = model_upsample.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('roc_auc_score:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling the data had some affect on the f1_score (0.48 to 0.5) and roc_auc_score and some affect on precision and recall, but the ratios are still basically the same as the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample function to decrease negative cases\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction factor: 0.1\n",
      "F1 unbalanced model: 0.42986425339366513\n",
      "F1 balanced model: 0.48047538200339557\n",
      "\n",
      "Fraction factor: 0.2\n",
      "F1 unbalanced model: 0.4791344667697063\n",
      "F1 balanced model: 0.48704663212435234\n",
      "\n",
      "Fraction factor: 0.30000000000000004\n",
      "F1 unbalanced model: 0.497164461247637\n",
      "F1 balanced model: 0.4939759036144578\n",
      "\n",
      "Fraction factor: 0.4\n",
      "F1 unbalanced model: 0.504875406283857\n",
      "F1 balanced model: 0.4918314703353396\n",
      "\n",
      "Fraction factor: 0.5\n",
      "F1 unbalanced model: 0.46886446886446886\n",
      "F1 balanced model: 0.4923076923076924\n",
      "\n",
      "Fraction factor: 0.6\n",
      "F1 unbalanced model: 0.4306864064602961\n",
      "F1 balanced model: 0.4888888888888888\n",
      "\n",
      "Fraction factor: 0.7000000000000001\n",
      "F1 unbalanced model: 0.3883211678832117\n",
      "F1 balanced model: 0.4901793339026473\n",
      "\n",
      "Fraction factor: 0.8\n",
      "F1 unbalanced model: 0.36785162287480677\n",
      "F1 balanced model: 0.48717948717948717\n",
      "\n",
      "Fraction factor: 0.9\n",
      "F1 unbalanced model: 0.36245954692556637\n",
      "F1 balanced model: 0.4905982905982907\n",
      "\n",
      "Best f1: 0.504875406283857 is at fraction = 0.4\n"
     ]
    }
   ],
   "source": [
    "# For loop to find the optimal fraction parameter for downsampling\n",
    "\n",
    "best_i = 0\n",
    "best_f1 = 0\n",
    "for i in np.arange(0.1, 1, 0.1):\n",
    "    features_downsampled, target_downsampled = downsample(features_train, target_train, i)\n",
    "\n",
    "    model_downsample = LogisticRegression(random_state=12345)\n",
    "    model_downsample.fit(features_downsampled, target_downsampled)\n",
    "    predicted_valid_downsample = model_downsample.predict(features_valid)\n",
    "    \n",
    "    print('Fraction factor:', i)\n",
    "    print('F1 unbalanced model:', f1_score(target_valid, predicted_valid_downsample))\n",
    "    if(f1_score(target_valid, predicted_valid_downsample) > best_f1):\n",
    "        best_f1 = f1_score(target_valid, predicted_valid_downsample)\n",
    "        best_i = i\n",
    "    \n",
    "    features_downsampled, target_downsampled = downsample(features_train, target_train, i)\n",
    "\n",
    "    model_downsample = LogisticRegression(class_weight= 'balanced', random_state=12345)\n",
    "    model_downsample.fit(features_downsampled, target_downsampled)\n",
    "    predicted_valid_downsample = model_downsample.predict(features_valid)\n",
    "\n",
    "    print('F1 balanced model:', f1_score(target_valid, predicted_valid_downsample))\n",
    "    if(f1_score(target_valid, predicted_valid_downsample) > best_f1):\n",
    "        best_f1 = f1_score(target_valid, predicted_valid_downsample)\n",
    "        best_i = i\n",
    "    print()\n",
    "print('Best f1:', best_f1, 'is at fraction =', best_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell above, fraction = 0.4 and no class_weight parameter gives the best f1_score of 0.5 which is basically the same as the results from upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.504875406283857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1582\n",
      "           1       0.46      0.56      0.50       418\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.67      0.69      0.68      2000\n",
      "weighted avg       0.79      0.77      0.78      2000\n",
      "\n",
      "roc_auc_score: 0.7625877848281201\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with best parameters for downsampling\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.4)\n",
    "model_downsample = LogisticRegression(random_state=12345)\n",
    "model_downsample.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid_downsample = model_downsample.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid_downsample))\n",
    "print(classification_report(target_valid, predicted_valid_downsample))\n",
    "\n",
    "probabilities_valid = model_downsample.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('roc_auc_score:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the f1_score and roc_auc_score were affected very little by downsampling.\n",
    "Next, the threshold for the barrier between negative classes and positive classes will be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3457402812241522 | 0.01\n",
      "0.3457402812241522 | 0.02\n",
      "0.3458833264377327 | 0.03\n",
      "0.346744089589382 | 0.04\n",
      "0.34746467165419787 | 0.05\n",
      "0.3493522774759716 | 0.060000000000000005\n",
      "0.3517038283550694 | 0.06999999999999999\n",
      "0.35604770017035775 | 0.08\n",
      "0.35815755488592343 | 0.09\n",
      "0.3633187772925764 | 0.09999999999999999\n",
      "0.3682342502218279 | 0.11\n",
      "0.37330928764652843 | 0.12\n",
      "0.3758573388203018 | 0.13\n",
      "0.3794063079777365 | 0.14\n",
      "0.38068448195030474 | 0.15000000000000002\n",
      "0.3888622179548728 | 0.16\n",
      "0.3944909001475652 | 0.17\n",
      "0.3975963945918878 | 0.18000000000000002\n",
      "0.4008117706747844 | 0.19\n",
      "0.40329218106995884 | 0.2\n",
      "0.40906694781233527 | 0.21000000000000002\n",
      "0.4122383252818036 | 0.22\n",
      "0.4161660294920808 | 0.23\n",
      "0.4202334630350194 | 0.24000000000000002\n",
      "0.4271954674220963 | 0.25\n",
      "0.4303065355696934 | 0.26\n",
      "0.43431952662721895 | 0.27\n",
      "0.4412296564195299 | 0.28\n",
      "0.44731977818853974 | 0.29000000000000004\n",
      "0.4524714828897338 | 0.3\n",
      "0.4596354166666667 | 0.31\n",
      "0.46728971962616817 | 0.32\n",
      "0.4726775956284153 | 0.33\n",
      "0.4738675958188153 | 0.34\n",
      "0.47394718058529617 | 0.35000000000000003\n",
      "0.4745269286754003 | 0.36000000000000004\n",
      "0.484984984984985 | 0.37\n",
      "0.4869431643625192 | 0.38\n",
      "0.4858490566037736 | 0.39\n",
      "0.48381877022653724 | 0.4\n",
      "0.48474855729596045 | 0.41000000000000003\n",
      "0.4836272040302267 | 0.42000000000000004\n",
      "0.4883920894239037 | 0.43\n",
      "0.4899387576552931 | 0.44\n",
      "0.4910071942446043 | 0.45\n",
      "0.49539594843462237 | 0.46\n",
      "0.5018867924528302 | 0.47000000000000003\n",
      "0.49616858237547895 | 0.48000000000000004\n",
      "0.4955752212389381 | 0.49\n",
      "0.5 | 0.5\n",
      "0.4969574036511157 | 0.51\n",
      "0.49331963001027757 | 0.52\n",
      "0.4911180773249739 | 0.53\n",
      "0.4924731182795699 | 0.54\n",
      "0.49944994499449946 | 0.55\n",
      "0.49496080627099664 | 0.56\n",
      "0.4850574712643679 | 0.5700000000000001\n",
      "0.48056537102473496 | 0.5800000000000001\n",
      "0.4752714113389626 | 0.59\n",
      "0.46609124537607893 | 0.6\n",
      "0.4582278481012658 | 0.61\n",
      "0.45302445302445304 | 0.62\n",
      "0.43766578249336874 | 0.63\n",
      "0.42530282637954236 | 0.64\n",
      "0.41369863013698627 | 0.65\n",
      "0.40787623066104084 | 0.66\n",
      "0.3942446043165468 | 0.67\n",
      "0.3911764705882353 | 0.68\n",
      "0.3778110944527736 | 0.6900000000000001\n",
      "0.36474164133738607 | 0.7000000000000001\n",
      "0.36024844720496896 | 0.7100000000000001\n",
      "0.3584905660377359 | 0.72\n",
      "0.35499207606973054 | 0.73\n",
      "0.34426229508196715 | 0.74\n",
      "0.3355932203389831 | 0.75\n",
      "0.32167832167832167 | 0.76\n",
      "0.30161579892280077 | 0.77\n",
      "0.28205128205128205 | 0.78\n",
      "0.2681564245810056 | 0.79\n",
      "0.25475285171102663 | 0.8\n",
      "0.22352941176470584 | 0.81\n",
      "0.21200000000000002 | 0.8200000000000001\n",
      "0.1951219512195122 | 0.8300000000000001\n",
      "0.16563146997929606 | 0.8400000000000001\n",
      "0.14799154334038053 | 0.85\n",
      "0.13675213675213677 | 0.86\n",
      "0.09606986899563319 | 0.87\n",
      "0.07606263982102907 | 0.88\n",
      "0.0632054176072235 | 0.89\n",
      "0.05922551252847381 | 0.9\n",
      "0.0547945205479452 | 0.91\n",
      "0.04597701149425287 | 0.92\n",
      "0.02331002331002331 | 0.93\n",
      "0.009389671361502346 | 0.9400000000000001\n",
      "0.009456264775413711 | 0.9500000000000001\n",
      "0.004761904761904762 | 0.9600000000000001\n",
      "0.004761904761904762 | 0.97\n",
      "0.0 | 0.98\n",
      "0.0 | 0.99\n",
      "Best f1_score 0.5018867924528302 is at threshold 0.47000000000000003\n"
     ]
    }
   ],
   "source": [
    "# Threshold adjust for upsampling case\n",
    "\n",
    "best_thresh = 0\n",
    "best_f1 = 0\n",
    "for i in np.arange(0.01, 1, 0.01):\n",
    "    pred_valid_upsample_new_threshold = (model_upsample.predict_proba(features_valid)[:, 1] >= i).astype(int) \n",
    "    print(f1_score(target_valid, pred_valid_upsample_new_threshold), '|', i)\n",
    "    if(f1_score(target_valid, pred_valid_upsample_new_threshold) > best_f1):\n",
    "        best_f1 = f1_score(target_valid, pred_valid_upsample_new_threshold)\n",
    "        best_thresh = i\n",
    "print('Best f1_score', best_f1, 'is at threshold', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After threshold adjustment, the best f1_score was 0.502 at fraction = 0.47, which is close to the default threshold. The results of this test is very similar to the results from previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3457402812241522\n",
      "0.3457402812241522\n",
      "0.34616977225672874\n",
      "0.3473203157457416\n",
      "0.3490605427974948\n",
      "0.3527426160337553\n",
      "0.3568075117370892\n",
      "0.3611111111111111\n",
      "0.3657243816254417\n",
      "0.3723021582733813\n",
      "0.37477148080438755\n",
      "0.3790060380863911\n",
      "0.3838862559241707\n",
      "0.39088263821532493\n",
      "0.39641434262948205\n",
      "0.397364419665484\n",
      "0.4045525090532851\n",
      "0.4092582851130984\n",
      "0.4152770306616461\n",
      "0.42041712403951703\n",
      "0.4244120940649496\n",
      "0.4278320874065555\n",
      "0.43309859154929575\n",
      "0.4370149253731343\n",
      "0.4441702652683529\n",
      "0.45022194039315155\n",
      "0.4601425793907971\n",
      "0.4687083888149134\n",
      "0.47282608695652173\n",
      "0.47671994440583737\n",
      "0.47285714285714286\n",
      "0.4815905743740795\n",
      "0.48599545798637384\n",
      "0.4797507788161993\n",
      "0.4796812749003984\n",
      "0.4816326530612245\n",
      "0.4887780548628429\n",
      "0.4868532654792196\n",
      "0.4891209747606614\n",
      "0.4920071047957371\n",
      "0.4872727272727272\n",
      "0.4902143522833177\n",
      "0.49382716049382713\n",
      "0.49466537342386024\n",
      "0.49950445986124875\n",
      "0.5010060362173039\n",
      "0.4938271604938271\n",
      "0.4952780692549842\n",
      "0.4989384288747345\n",
      "0.504875406283857\n",
      "0.5027932960893856\n",
      "0.49371428571428577\n",
      "0.48894062863795107\n",
      "0.4791418355184744\n",
      "0.4690157958687728\n",
      "0.46326276463262767\n",
      "0.45901639344262296\n",
      "0.45103092783505155\n",
      "0.43650793650793646\n",
      "0.4217687074829932\n",
      "0.4094052558782849\n",
      "0.401685393258427\n",
      "0.39544807965860596\n",
      "0.3971014492753623\n",
      "0.38575667655786355\n",
      "0.3802395209580838\n",
      "0.37575757575757573\n",
      "0.365891472868217\n",
      "0.35275590551181096\n",
      "0.337620578778135\n",
      "0.33552631578947373\n",
      "0.32367972742759793\n",
      "0.3217993079584775\n",
      "0.3074204946996466\n",
      "0.28467153284671537\n",
      "0.2654205607476635\n",
      "0.25475285171102663\n",
      "0.24324324324324328\n",
      "0.21696252465483234\n",
      "0.20040080160320642\n",
      "0.1906693711967546\n",
      "0.16563146997929606\n",
      "0.1395348837209302\n",
      "0.1284796573875803\n",
      "0.10457516339869281\n",
      "0.08869179600886917\n",
      "0.07191011235955057\n",
      "0.05895691609977325\n",
      "0.0547945205479452\n",
      "0.045871559633027525\n",
      "0.04597701149425287\n",
      "0.032407407407407406\n",
      "0.009389671361502346\n",
      "0.009411764705882352\n",
      "0.009501187648456056\n",
      "0.004761904761904762\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Best f1_score 0.504875406283857 is at threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "# Threshold adjust for downsampling case\n",
    "\n",
    "best_thresh = 0\n",
    "best_f1 = 0\n",
    "for i in np.arange(0.01, 1, 0.01):\n",
    "    pred_valid_downsample_new_threshold = (model_downsample.predict_proba(features_valid)[:, 1] >= i).astype(int) \n",
    "    print(f1_score(target_valid, pred_valid_downsample_new_threshold))\n",
    "    if(f1_score(target_valid, pred_valid_downsample_new_threshold) > best_f1):\n",
    "        best_f1 = f1_score(target_valid, pred_valid_downsample_new_threshold)\n",
    "        best_thresh = i\n",
    "print('Best f1_score', best_f1, 'is at threshold', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After threshold adjustment, the best f1_score was 0.505 at fraction = 0.5, which is the default threshold. The results of this test is very similar to the results from previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4473975636766334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84      1577\n",
      "           1       0.42      0.48      0.45       423\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.64      0.65      0.64      2000\n",
      "weighted avg       0.76      0.75      0.76      2000\n",
      "\n",
      "roc_auc_score: 0.7422448285115077\n"
     ]
    }
   ],
   "source": [
    "# Optimal Logistic Regression model found will be used on test set to calculate f1_score\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.4)\n",
    "model_downsample = LogisticRegression(random_state=12345)\n",
    "model_downsample.fit(features_downsampled, target_downsampled)\n",
    "predicted_test_downsample = model_downsample.predict(features_test)\n",
    "\n",
    "print('F1:', f1_score(target_test, predicted_test_downsample))\n",
    "print(classification_report(target_test, predicted_test_downsample))\n",
    "\n",
    "probabilities_test = model_downsample.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('roc_auc_score:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing and tuning with a Logistic Regression, the model can not produce a f1_score higher than 0.505 and this was achieved with downsampling with a fraction parameter = 0.4 and no class_weight parameter. Its corresponding roc_auc_score is 0.76, which is very similar to the previous models. Using the test set, the model it fairly worse with a f1_score of 0.45 and a roc_auc_score of 0.74. I conclude that a different model needs to be analyzed since a Logistic Regression is not adequate to meet the f1_score threshold of 0.59 or higher. To achieve a higher f1_score, a Decision Tree Classifier will be used next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next section will be adjusting and tuning a Decision Tree Classifier to get the best f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  float64\n",
      " 1   Geography        10000 non-null  float64\n",
      " 2   Gender           10000 non-null  float64\n",
      " 3   Age              10000 non-null  float64\n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  float64\n",
      " 7   HasCrCard        10000 non-null  float64\n",
      " 8   IsActiveMember   10000 non-null  float64\n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 859.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for a Decision Tree Classifier\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)\n",
    "\n",
    "features_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the numerical features\n",
    "data_ordinal[features_to_scale] = scaler.fit_transform(data_ordinal[features_to_scale])\n",
    "\n",
    "# Display the first few rows of the preprocessed dataset\n",
    "print(data_ordinal.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (6000, 11), (6000,)\n",
      "Validation set: (2000, 11), (2000,)\n",
      "Test set: (2000, 11), (2000,)\n",
      "\n",
      "F1: 0.45985401459854014\n",
      "roc_auc_score: 0.6581245954790436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86      1582\n",
      "         1.0       0.47      0.45      0.46       418\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.66      0.66      0.66      2000\n",
      "weighted avg       0.78      0.78      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training, validation, and testing sets\n",
    "\n",
    "# Creating features list and target list\n",
    "target_x = data_ordinal['Exited']\n",
    "features_x = data_ordinal.drop(columns=['Exited'])\n",
    "\n",
    "# Splitting into training (60%) and temporary (40%). Used random_state=12345 as shown in the sprint.\n",
    "features_train_x, features_temp_x, target_train_x, target_temp_x = train_test_split(features_x, target_x, test_size=0.4, random_state=12345)\n",
    "\n",
    "# Splitting the temporary set into validation (20%) and test (20%)\n",
    "features_valid_x, features_test_x, target_valid_x, target_test_x = train_test_split(features_temp_x, target_temp_x, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Verify the sizes of the splits following the traditional 3:1:1 split.\n",
    "print(f'Training set: {features_train.shape}, {target_train.shape}')\n",
    "print(f'Validation set: {features_valid.shape}, {target_valid.shape}')\n",
    "print(f'Test set: {features_test.shape}, {target_test.shape}')\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=12345)\n",
    "tree_model.fit(features_train_x, target_train_x)\n",
    "predicted_tree_valid = tree_model.predict(features_valid_x)\n",
    "\n",
    "f1_tree_valid = f1_score(target_valid_x,predicted_tree_valid)\n",
    "print('F1:', f1_tree_valid)\n",
    "\n",
    "probabilities_valid_x = tree_model.predict_proba(features_valid_x)\n",
    "probabilities_one_valid_x = probabilities_valid_x[:, 1]\n",
    "\n",
    "roc_auc_x = roc_auc_score(target_valid_x, probabilities_one_valid_x)\n",
    "print('roc_auc_score:', roc_auc_x)\n",
    "print(classification_report(target_valid_x, probabilities_one_valid_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running a Decision Tree Classifier, the base f1_score is about 0.46 and a roc_auc_score of about 0.66. The f1 score is better than the base line for a Logistic Regression but has a worse roc_auc_score compared to the Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 1 : 0.4994903160040775\n",
      "depth: 2 : 0.541015625\n",
      "depth: 3 : 0.541015625\n",
      "depth: 4 : 0.5277777777777778\n",
      "depth: 5 : 0.5894962486602359\n",
      "depth: 6 : 0.5497287522603979\n",
      "depth: 7 : 0.5396536007292617\n",
      "depth: 8 : 0.5357142857142858\n",
      "depth: 9 : 0.5290068829891839\n",
      "depth: 10 : 0.5054509415262636\n",
      "depth: 11 : 0.49845520082389294\n",
      "depth: 12 : 0.4849115504682622\n",
      "depth: 13 : 0.49073064340239914\n",
      "depth: 14 : 0.4955555555555556\n",
      "depth: 15 : 0.48735632183908045\n",
      "depth: 16 : 0.4820143884892086\n",
      "depth: 17 : 0.47086801426872776\n",
      "depth: 18 : 0.48375451263537905\n",
      "depth: 19 : 0.4789410348977136\n",
      "depth: 20 : 0.47746650426309384\n",
      "depth: 21 : 0.4833538840937115\n",
      "depth: 22 : 0.47940074906367036\n",
      "depth: 23 : 0.47940074906367036\n",
      "depth: 24 : 0.47940074906367036\n",
      "depth: 25 : 0.47940074906367036\n",
      "depth: 26 : 0.47940074906367036\n",
      "depth: 27 : 0.47940074906367036\n",
      "depth: 28 : 0.47940074906367036\n",
      "depth: 29 : 0.47940074906367036\n",
      "Best f1 is at max depth 5 with an f1_score of 0.5894962486602359\n"
     ]
    }
   ],
   "source": [
    "# Running a Decision Tree Classifier with different max_depth integers and class_weight = 'balanced'\n",
    "\n",
    "# Initializing the best_f1 and best_depth values to store the best f1 score and the corresponding max depth\n",
    "best_f1 = 0\n",
    "best_depth = 0\n",
    "# Loop to change the max_depth parameter to find the optimal max_depth for highest f1 score\n",
    "for depth in range(1,30):\n",
    "    \n",
    "    tree_model = DecisionTreeClassifier(class_weight = \"balanced\", random_state=12345, max_depth=depth)\n",
    "    tree_model.fit(features_train_x, target_train_x) # train model on training set\n",
    "    tree_pred = tree_model.predict(features_valid_x) # find the predictions using validation set\n",
    "    tree_f1 = f1_score(target_valid_x, tree_pred) # get accuracy of model on validation set\n",
    "    \n",
    "    # Store the best accuracy and corresponding max_depth\n",
    "    if(tree_f1 > best_f1):\n",
    "        best_f1 = tree_f1\n",
    "        best_depth = depth\n",
    "    \n",
    "    print(\"depth:\", depth, end=' : ')\n",
    "    print(tree_f1)\n",
    "print(\"Best f1 is at max depth\", best_depth, \"with an f1_score of\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 1 : 0.0\n",
      "depth: 2 : 0.5217391304347825\n",
      "depth: 3 : 0.4234875444839857\n",
      "depth: 4 : 0.5528700906344411\n",
      "depth: 5 : 0.5169628432956381\n",
      "depth: 6 : 0.5360501567398119\n",
      "depth: 7 : 0.5106382978723405\n",
      "depth: 8 : 0.5379939209726444\n",
      "depth: 9 : 0.5325443786982248\n",
      "depth: 10 : 0.5007194244604317\n",
      "depth: 11 : 0.5210312075983717\n",
      "depth: 12 : 0.5169712793733682\n",
      "depth: 13 : 0.5052910052910053\n",
      "depth: 14 : 0.48578811369509045\n",
      "depth: 15 : 0.465\n",
      "depth: 16 : 0.4825\n",
      "depth: 17 : 0.48507462686567165\n",
      "depth: 18 : 0.4668304668304668\n",
      "depth: 19 : 0.46398046398046394\n",
      "depth: 20 : 0.4560099132589839\n",
      "depth: 21 : 0.4678787878787879\n",
      "depth: 22 : 0.4678787878787879\n",
      "depth: 23 : 0.4768856447688565\n",
      "depth: 24 : 0.45985401459854014\n",
      "depth: 25 : 0.45985401459854014\n",
      "depth: 26 : 0.45985401459854014\n",
      "depth: 27 : 0.45985401459854014\n",
      "depth: 28 : 0.45985401459854014\n",
      "depth: 29 : 0.45985401459854014\n",
      "Best f1 is at max depth 4 with an f1_score of 0.5528700906344411\n"
     ]
    }
   ],
   "source": [
    "# Running a Decision Tree Classifier with different max_depth integers and no class_weight parameter\n",
    "\n",
    "# Initializing the best_f1 and best_depth values to store the best f1 score and the corresponding max depth\n",
    "best_f1 = 0\n",
    "best_depth = 0\n",
    "# Loop to change the max_depth parameter to find the optimal max_depth for highest f1 score\n",
    "for depth in range(1,30):\n",
    "    \n",
    "    tree_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    tree_model.fit(features_train_x, target_train_x) # train model on training set\n",
    "    tree_pred = tree_model.predict(features_valid_x) # find the predictions using validation set\n",
    "    tree_f1 = f1_score(target_valid_x, tree_pred) # get accuracy of model on validation set\n",
    "    \n",
    "    # Store the best accuracy and corresponding max_depth\n",
    "    if(tree_f1 > best_f1):\n",
    "        best_f1 = tree_f1\n",
    "        best_depth = depth\n",
    "    \n",
    "    print(\"depth:\", depth, end=' : ')\n",
    "    print(tree_f1)\n",
    "print(\"Best f1 is at max depth\", best_depth, \"with an f1_score of\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5894962486602359\n",
      "roc_auc_score: 0.8197447056902112\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with optimal max_depth and optimal class_weight parameter\n",
    "\n",
    "tree_model = DecisionTreeClassifier(class_weight = 'balanced', random_state=12345, max_depth=5)  # create a model, specify n_estimators=est\n",
    "tree_model.fit(features_train_x, target_train_x) # train model on training set\n",
    "tree_pred = tree_model.predict(features_valid_x) # find the predictions using validation set\n",
    "tree_f1 = f1_score(target_valid_x, tree_pred) # get accuracy of model on validation set\n",
    "print('F1:', tree_f1)\n",
    "\n",
    "probabilities_valid_x = tree_model.predict_proba(features_valid_x)\n",
    "probabilities_one_valid_x = probabilities_valid_x[:, 1]\n",
    "\n",
    "roc_auc_x = roc_auc_score(target_valid_x, probabilities_one_valid_x)\n",
    "print('roc_auc_score:', roc_auc_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Classifier with class_weight = 'balanced' and max_depth = 5 gives a f1_score of 0.589, which is the best f1_score achieved so far. The roc_auc_score is 0.82 which is also the best roc_auc_score so far indicating that the model is better than a Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next upsampling, downsampling and threshold adjusetments will be used to achieve a higer f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "Best f1: 0.5894962486602359 | best repeat factor: 1\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with upsampling and class_weight = 'balanced'\n",
    "\n",
    "# Finding optimal repeat factor\n",
    "best_i = 0\n",
    "best_f1 = 0\n",
    "for i in range(1,10):\n",
    "    features_upsampled_x, target_upsampled_x = upsample(features_train_x, target_train_x, i)\n",
    "    \n",
    "    model_upsample_x = DecisionTreeClassifier(class_weight = 'balanced', random_state=12345, max_depth = 5)\n",
    "    model_upsample_x.fit(features_upsampled_x, target_upsampled_x)\n",
    "    predicted_valid_upsample_x = model_upsample_x.predict(features_valid_x)\n",
    "\n",
    "    print('F1:', f1_score(target_valid_x, predicted_valid_upsample_x))\n",
    "    if(f1_score(target_valid_x, predicted_valid_upsample_x) > best_f1):\n",
    "        best_f1 = f1_score(target_valid_x, predicted_valid_upsample_x)\n",
    "        best_i = i\n",
    "print('Best f1:', best_f1, '| best repeat factor:', best_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With upsampling, the f1_score remained the same with every repeat factor. Next will be finding the optimal repeat factor without the class_weight parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5169628432956381\n",
      "F1: 0.6048284625158831\n",
      "F1: 0.6082004555808656\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5315555555555556\n",
      "F1: 0.5482493595217763\n",
      "F1: 0.5118050266565118\n",
      "F1: 0.4743758212877793\n",
      "F1: 0.4588688946015424\n",
      "Best f1: 0.6082004555808656 | best repeat factor: 3\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with upsampling and no class_weight parameter\n",
    "\n",
    "# Finding optimal repeat factor\n",
    "best_i = 0\n",
    "best_f1 = 0\n",
    "for i in range(1,10):\n",
    "    features_upsampled_x, target_upsampled_x = upsample(features_train_x, target_train_x, i)\n",
    "    \n",
    "    model_upsample_x = DecisionTreeClassifier(random_state=12345, max_depth = 5)\n",
    "    model_upsample_x.fit(features_upsampled_x, target_upsampled_x)\n",
    "    predicted_valid_upsample_x = model_upsample_x.predict(features_valid_x)\n",
    "\n",
    "    print('F1:', f1_score(target_valid_x, predicted_valid_upsample_x))\n",
    "    if(f1_score(target_valid_x, predicted_valid_upsample_x) > best_f1):\n",
    "        best_f1 = f1_score(target_valid_x, predicted_valid_upsample_x)\n",
    "        best_i = i\n",
    "print('Best f1:', best_f1, '| best repeat factor:', best_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6082004555808656\n",
      "roc_auc_score: 0.8302123470381504\n"
     ]
    }
   ],
   "source": [
    "# Optimal Decision Tree Classifier with upsampling\n",
    "\n",
    "features_upsampled_x, target_upsampled_x = upsample(features_train_x, target_train_x, 3)\n",
    "    \n",
    "model_upsample_x = DecisionTreeClassifier(random_state=12345, max_depth = 5)\n",
    "model_upsample_x.fit(features_upsampled_x, target_upsampled_x)\n",
    "predicted_valid_upsample_x = model_upsample_x.predict(features_valid_x)\n",
    "\n",
    "print('F1:', f1_score(target_valid_x, predicted_valid_upsample_x))\n",
    "\n",
    "probabilities_valid_x = model_upsample_x.predict_proba(features_valid_x)\n",
    "probabilities_one_valid_x = probabilities_valid_x[:, 1]\n",
    "\n",
    "roc_auc_x = roc_auc_score(target_valid_x, probabilities_one_valid_x)\n",
    "print('roc_auc_score:', roc_auc_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After upsampling, the model performs the best without a class_weight parameter and a max_depth = 5 and an upsampling repeat factor of 3 which computes a  f1_score of 0.6 and a corresponding roc_auc_score of 0.83, both of which are the best so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34451345755693585\n",
      "0.34451345755693585\n",
      "0.38295880149812733\n",
      "0.38295880149812733\n",
      "0.38295880149812733\n",
      "0.38295880149812733\n",
      "0.38295880149812733\n",
      "0.38295880149812733\n",
      "0.38295880149812733\n",
      "0.4005979073243648\n",
      "0.4005979073243648\n",
      "0.4005979073243648\n",
      "0.4133611691022964\n",
      "0.4133611691022964\n",
      "0.4133611691022964\n",
      "0.4477784189267167\n",
      "0.4477784189267167\n",
      "0.4477784189267167\n",
      "0.4477784189267167\n",
      "0.4477784189267167\n",
      "0.4477784189267167\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.4891304347826087\n",
      "0.5125925925925926\n",
      "0.5125925925925926\n",
      "0.5125925925925926\n",
      "0.5125925925925926\n",
      "0.5125925925925926\n",
      "0.5125925925925926\n",
      "0.5205267234701781\n",
      "0.5205267234701781\n",
      "0.5179968701095461\n",
      "0.572541382667965\n",
      "0.572541382667965\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.5963791267305644\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6082004555808656\n",
      "0.6047678795483061\n",
      "0.557037037037037\n",
      "0.557037037037037\n",
      "0.557037037037037\n",
      "0.557037037037037\n",
      "0.557037037037037\n",
      "0.557037037037037\n",
      "0.5372670807453416\n",
      "0.5372670807453416\n",
      "0.5372670807453416\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.5218800648298217\n",
      "0.47469458987783597\n",
      "0.47469458987783597\n",
      "0.39106145251396646\n",
      "0.39106145251396646\n",
      "0.39106145251396646\n",
      "0.39106145251396646\n",
      "0.39106145251396646\n",
      "0.39106145251396646\n",
      "0.3850467289719627\n",
      "0.1735357917570499\n",
      "0.1415929203539823\n",
      "0.1415929203539823\n",
      "0.1415929203539823\n",
      "Best f1_score is 0.6082004555808656 at threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "# Threshold adjustment on upsampling\n",
    "\n",
    "best_f1 = 0\n",
    "best_thresh = 0\n",
    "for i in np.arange(0.01, 1, 0.01):\n",
    "    pred_valid_upsample_new_threshold_x = (model_upsample_x.predict_proba(features_valid_x)[:, 1] >= i).astype(int) \n",
    "    print(f1_score(target_valid_x, pred_valid_upsample_new_threshold_x))\n",
    "    \n",
    "    if(f1_score(target_valid_x, pred_valid_upsample_new_threshold_x) > best_f1):\n",
    "        best_f1 = f1_score(target_valid_x, pred_valid_upsample_new_threshold_x)\n",
    "        best_thresh = i\n",
    "print('Best f1_score is', best_f1, 'at threshold', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With threshold adjustments, the model got the best f1_score of 0.6 at threshold = 0.5, which is the default threshold. So, threshold adjustment did not improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.35137457044673537\n",
      "F1: 0.36028751123090746\n",
      "F1: 0.36061269146608316\n",
      "F1: 0.4053497942386831\n",
      "F1: 0.40906694781233527\n",
      "F1: 0.42286348501664817\n",
      "F1: 0.4097258147956544\n",
      "F1: 0.4117021276595745\n",
      "F1: 0.43956043956043955\n",
      "F1: 0.4374649467190129\n",
      "F1: 0.48951994590939824\n",
      "F1: 0.48275862068965525\n",
      "F1: 0.5172413793103449\n",
      "F1: 0.5141158989598811\n",
      "F1: 0.526148969889065\n",
      "F1: 0.5255704169944925\n",
      "F1: 0.5263987391646966\n",
      "F1: 0.510894064613073\n",
      "F1: 0.5289912629070691\n",
      "F1: 0.5283911671924291\n",
      "F1: 0.5598621877691645\n",
      "F1: 0.5598621877691645\n",
      "F1: 0.5494313210848645\n",
      "F1: 0.5441819772528435\n",
      "F1: 0.5435540069686412\n",
      "F1: 0.5432314410480349\n",
      "F1: 0.562091503267974\n",
      "F1: 0.5629077353215284\n",
      "F1: 0.5568281938325991\n",
      "F1: 0.5633802816901409\n",
      "F1: 0.5633802816901409\n",
      "F1: 0.5662778366914104\n",
      "F1: 0.5642633228840125\n",
      "F1: 0.5655172413793103\n",
      "F1: 0.5800214822771214\n",
      "F1: 0.5655471289274107\n",
      "F1: 0.5911214953271028\n",
      "F1: 0.5746864310148233\n",
      "F1: 0.5760171306209849\n",
      "F1: 0.5693581780538303\n",
      "F1: 0.5858369098712447\n",
      "F1: 0.5858369098712447\n",
      "F1: 0.5849462365591399\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5695708712613784\n",
      "F1: 0.578343949044586\n",
      "F1: 0.578343949044586\n",
      "F1: 0.578343949044586\n",
      "F1: 0.578343949044586\n",
      "F1: 0.578343949044586\n",
      "F1: 0.59\n",
      "F1: 0.59\n",
      "F1: 0.556390977443609\n",
      "F1: 0.556390977443609\n",
      "F1: 0.556390977443609\n",
      "F1: 0.556390977443609\n",
      "F1: 0.5555555555555555\n",
      "F1: 0.5555555555555555\n",
      "F1: 0.5555555555555555\n",
      "F1: 0.5555555555555555\n",
      "F1: 0.555052790346908\n",
      "F1: 0.555052790346908\n",
      "F1: 0.555052790346908\n",
      "F1: 0.555052790346908\n",
      "F1: 0.555052790346908\n",
      "F1: 0.555052790346908\n",
      "F1: 0.5247999999999999\n",
      "F1: 0.5247999999999999\n",
      "F1: 0.5247999999999999\n",
      "F1: 0.5247999999999999\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5572289156626506\n",
      "F1: 0.5572289156626506\n",
      "F1: 0.5572289156626506\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5271565495207668\n",
      "F1: 0.5279999999999999\n",
      "F1: 0.5279999999999999\n",
      "F1: 0.5279999999999999\n",
      "F1: 0.5081967213114753\n",
      "F1: 0.5081967213114753\n",
      "F1: 0.5081967213114753\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5256410256410257\n",
      "F1: 0.5169628432956381\n",
      "Best f1: 0.5911214953271028 | frac = 0.37\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with downsampling\n",
    "\n",
    "# Finding optimal fraction factor with no class_weight parameter\n",
    "best_i = 0\n",
    "best_f1 = 0\n",
    "for i in np.arange(0.01,1,0.01):\n",
    "    features_downsampled_x, target_downsampled_x = downsample(features_train_x, target_train_x, i) \n",
    "    model_downsample_x = DecisionTreeClassifier(random_state=12345, max_depth = 5)\n",
    "    model_downsample_x.fit(features_downsampled_x, target_downsampled_x)\n",
    "    predicted_valid_downsample_x = model_downsample_x.predict(features_valid_x)\n",
    "    print('F1:', f1_score(target_valid_x, predicted_valid_downsample_x))\n",
    "    if(f1_score(target_valid_x, predicted_valid_downsample_x) > best_f1):\n",
    "        best_f1 = f1_score(target_valid_x, predicted_valid_downsample_x)\n",
    "        best_i = i\n",
    "print('Best f1:', best_f1, '| frac =', best_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4667802385008518\n",
      "F1: 0.48730158730158724\n",
      "F1: 0.5012658227848101\n",
      "F1: 0.5361930294906166\n",
      "F1: 0.526\n",
      "F1: 0.541958041958042\n",
      "F1: 0.578383641674781\n",
      "F1: 0.5615763546798029\n",
      "F1: 0.5390835579514824\n",
      "F1: 0.5334448160535118\n",
      "F1: 0.5445544554455446\n",
      "F1: 0.539159109645507\n",
      "F1: 0.5190380761523047\n",
      "F1: 0.5552511415525114\n",
      "F1: 0.5546372819100092\n",
      "F1: 0.5589600742804086\n",
      "F1: 0.5297670405522001\n",
      "F1: 0.5612343297974928\n",
      "F1: 0.5635148042024832\n",
      "F1: 0.5449688334817454\n",
      "F1: 0.5329861111111112\n",
      "F1: 0.5598621877691645\n",
      "F1: 0.546562228024369\n",
      "F1: 0.546562228024369\n",
      "F1: 0.5445026178010471\n",
      "F1: 0.5445026178010471\n",
      "F1: 0.5296108291032149\n",
      "F1: 0.5445026178010471\n",
      "F1: 0.5445026178010471\n",
      "F1: 0.5435540069686412\n",
      "F1: 0.5445026178010471\n",
      "F1: 0.5445026178010471\n",
      "F1: 0.5482416591523896\n",
      "F1: 0.5471014492753624\n",
      "F1: 0.5579150579150579\n",
      "F1: 0.5589941972920697\n",
      "F1: 0.5631067961165048\n",
      "F1: 0.5642023346303501\n",
      "F1: 0.5653021442495126\n",
      "F1: 0.56640625\n",
      "F1: 0.5876068376068377\n",
      "F1: 0.5884861407249468\n",
      "F1: 0.5851063829787234\n",
      "F1: 0.5653021442495126\n",
      "F1: 0.5653021442495126\n",
      "F1: 0.5884861407249468\n",
      "F1: 0.5884861407249468\n",
      "F1: 0.5884861407249468\n",
      "F1: 0.5884861407249468\n",
      "F1: 0.5471349353049908\n",
      "F1: 0.5685884691848907\n",
      "F1: 0.5685884691848907\n",
      "F1: 0.5685884691848907\n",
      "F1: 0.5848452508004269\n",
      "F1: 0.5848452508004269\n",
      "F1: 0.5833333333333333\n",
      "F1: 0.5848452508004269\n",
      "F1: 0.5828933474128828\n",
      "F1: 0.6075949367088608\n",
      "F1: 0.6052332195676906\n",
      "F1: 0.6052332195676906\n",
      "F1: 0.5983701979045403\n",
      "F1: 0.6052332195676906\n",
      "F1: 0.6052332195676906\n",
      "F1: 0.6052332195676906\n",
      "F1: 0.6052332195676906\n",
      "F1: 0.5979381443298969\n",
      "F1: 0.5979381443298969\n",
      "F1: 0.5979381443298969\n",
      "F1: 0.5979381443298969\n",
      "F1: 0.5963302752293579\n",
      "F1: 0.5995423340961099\n",
      "F1: 0.5995423340961099\n",
      "F1: 0.5995423340961099\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5995423340961099\n",
      "F1: 0.6000000000000001\n",
      "F1: 0.6000000000000001\n",
      "F1: 0.5995423340961099\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.59830866807611\n",
      "F1: 0.59830866807611\n",
      "F1: 0.59830866807611\n",
      "F1: 0.59830866807611\n",
      "F1: 0.5900216919739696\n",
      "F1: 0.5900216919739696\n",
      "F1: 0.5900216919739696\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5900216919739696\n",
      "F1: 0.5900216919739696\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "F1: 0.5894962486602359\n",
      "Best f1: 0.6075949367088608 | frac = 0.59\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with downsampling\n",
    "\n",
    "# Finding optimal fraction factor with class_weight = 'balanced'\n",
    "best_i = 0\n",
    "best_f1 = 0\n",
    "for i in np.arange(0.01,1,0.01):\n",
    "    features_downsampled_x, target_downsampled_x = downsample(features_train_x, target_train_x, i) \n",
    "    model_downsample_x = DecisionTreeClassifier(class_weight = 'balanced', random_state=12345, max_depth = 5)\n",
    "    model_downsample_x.fit(features_downsampled_x, target_downsampled_x)\n",
    "    predicted_valid_downsample_x = model_downsample_x.predict(features_valid_x)\n",
    "    print('F1:', f1_score(target_valid_x, predicted_valid_downsample_x))\n",
    "    if(f1_score(target_valid_x, predicted_valid_downsample_x) > best_f1):\n",
    "        best_f1 = f1_score(target_valid_x, predicted_valid_downsample_x)\n",
    "        best_i = i\n",
    "print('Best f1:', best_f1, '| frac =', best_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6075949367088608\n",
      "roc_auc_score: 0.7566870716614544\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with optimal parameters \n",
    "\n",
    "features_downsampled_x, target_downsampled_x = downsample(features_train_x, target_train_x, 0.59) \n",
    "model_downsample_x = DecisionTreeClassifier(class_weight = 'balanced',random_state=12345, max_depth = 5)\n",
    "model_downsample_x.fit(features_downsampled_x, target_downsampled_x)\n",
    "predicted_valid_downsample_x = model_downsample_x.predict(features_valid_x)\n",
    "print('F1:', f1_score(target_valid_x, predicted_valid_downsample_x))\n",
    "print('roc_auc_score:', roc_auc_score(target_valid_x, predicted_valid_downsample_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With downsampling, the highest f1_score achieved is 0.6 with a corresponding roc_auc_score of 0.76, both are not as good as with upsampling. Next, threshold adjustment with downsampling will be used to see if the f1_score can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3443708609271523\n",
      "0.3443708609271523\n",
      "0.3827795975666823\n",
      "0.3827795975666823\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.3870967741935484\n",
      "0.405255179383527\n",
      "0.405255179383527\n",
      "0.405255179383527\n",
      "0.405255179383527\n",
      "0.405255179383527\n",
      "0.405255179383527\n",
      "0.432819383259912\n",
      "0.432819383259912\n",
      "0.432819383259912\n",
      "0.432819383259912\n",
      "0.432819383259912\n",
      "0.432819383259912\n",
      "0.43309272626318707\n",
      "0.43309272626318707\n",
      "0.43309272626318707\n",
      "0.4710526315789474\n",
      "0.4710526315789474\n",
      "0.4710526315789474\n",
      "0.4710526315789474\n",
      "0.4710526315789474\n",
      "0.4710526315789474\n",
      "0.4710526315789474\n",
      "0.49927431059506533\n",
      "0.49927431059506533\n",
      "0.49927431059506533\n",
      "0.49927431059506533\n",
      "0.49927431059506533\n",
      "0.49927431059506533\n",
      "0.49927431059506533\n",
      "0.49670329670329677\n",
      "0.5139220365950675\n",
      "0.5139220365950675\n",
      "0.5139220365950675\n",
      "0.5139220365950675\n",
      "0.5848452508004269\n",
      "0.5848452508004269\n",
      "0.5848452508004269\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6075949367088608\n",
      "0.6040609137055838\n",
      "0.6040609137055838\n",
      "0.5555555555555555\n",
      "0.5555555555555555\n",
      "0.5555555555555555\n",
      "0.5555555555555555\n",
      "0.5254777070063694\n",
      "0.5254777070063694\n",
      "0.5254777070063694\n",
      "0.5254777070063694\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.5073649754500817\n",
      "0.4832214765100671\n",
      "0.4832214765100671\n",
      "0.4832214765100671\n",
      "0.4832214765100671\n",
      "0.39033457249070624\n",
      "0.39033457249070624\n",
      "0.39033457249070624\n",
      "0.39033457249070624\n",
      "0.35067437379576105\n",
      "0.34108527131782945\n",
      "0.34108527131782945\n",
      "0.1535087719298246\n",
      "0.1535087719298246\n",
      "Best f1_score is 0.6075949367088608 at threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "# Downsampling with threshold adjustment\n",
    "\n",
    "best_f1 = 0\n",
    "best_thresh = 0\n",
    "for i in np.arange(0.01,1,0.01):\n",
    "    pred_valid_downsample_new_threshold_x = (model_downsample_x.predict_proba(features_valid_x)[:, 1] >= i).astype(int) \n",
    "    print(f1_score(target_valid_x, pred_valid_downsample_new_threshold_x))\n",
    "    \n",
    "    if(f1_score(target_valid_x, pred_valid_downsample_new_threshold_x) > best_f1):\n",
    "        best_f1 = f1_score(target_valid_x, pred_valid_downsample_new_threshold_x)\n",
    "        best_thresh = i\n",
    "print('Best f1_score is', best_f1, 'at threshold', best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold adjustment with down sampling did not affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5963718820861679\n",
      "roc_auc_score: 0.7487313944092907\n"
     ]
    }
   ],
   "source": [
    "# Optimal Decision Tree Classifer model found will be on test set to calculate f1_score\n",
    "\n",
    "features_downsampled_x, target_downsampled_x = downsample(features_train_x, target_train_x, 0.59) \n",
    "model_downsample_x = DecisionTreeClassifier(class_weight = 'balanced',random_state=12345, max_depth = 5)\n",
    "model_downsample_x.fit(features_downsampled_x, target_downsampled_x)\n",
    "predicted_test_downsample_x = model_downsample_x.predict(features_test_x)\n",
    "print('F1:', f1_score(target_test_x, predicted_test_downsample_x))\n",
    "print('roc_auc_score:', roc_auc_score(target_test_x, predicted_test_downsample_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, a Decision Tree Classifier is an adequate model for predicting if a customer will end their membership with the bank or not. I chose to focus on Logistic Regressions and Decision Tree Classifiers due to their simplicity and ability to work with its parameters. For both models, I tuned the hyper parameters, applied upsampling and downsampling to the features and targets sets, and adjusted the threshold for classification on positive and negative classes. After working with a Logistic Regression, I came to the conclusion that is not robust enough to achieve a higher f1 score than around 0.5 on the validation set. When tested with the test set, it produced a f1_score = 0.44 meaning it is a poor model overall. With a Decision Tree Classifier, a f1 score of 0.6 was achieved on the validation set by tuning its max_depth parameter, class_weight parameter and adjusting the repeat parameter in an upsampling method. The f1 score of 0.6 shows that the model is moderate and reasonably good at identifying positive and negative classes. The corresponding roc_auc_score of 0.75 shows that the model has good discriminatory power. When the most optimal model was tested on the test set, it computed a f1_score of 0.596 and a roc_auc_score of around 0.75. The model is fairly effective at distinguishing between the positive and negative classes. Overall, the model can adequately distinguish between a customer exiting or staying but it does not balance the precision and recall well and this is most likely due to the imbalance of classes in the raw data set. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1214,
    "start_time": "2024-07-28T06:36:30.054Z"
   },
   {
    "duration": 49,
    "start_time": "2024-07-28T06:37:00.012Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-28T06:37:17.531Z"
   },
   {
    "duration": 190,
    "start_time": "2024-07-28T06:39:42.393Z"
   },
   {
    "duration": 36,
    "start_time": "2024-07-28T06:39:52.615Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-28T06:41:13.361Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-28T06:42:32.227Z"
   },
   {
    "duration": 310,
    "start_time": "2024-07-28T08:17:34.123Z"
   },
   {
    "duration": 1250,
    "start_time": "2024-07-28T08:17:37.605Z"
   },
   {
    "duration": 63,
    "start_time": "2024-07-28T08:17:39.863Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-28T08:17:41.027Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-28T08:17:41.973Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-28T08:17:43.047Z"
   },
   {
    "duration": 1453,
    "start_time": "2024-07-28T08:17:44.544Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-28T08:18:16.566Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-28T08:18:20.973Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-28T08:18:25.759Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-28T08:19:05.986Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-28T08:19:16.782Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-28T08:19:28.127Z"
   },
   {
    "duration": 54,
    "start_time": "2024-07-28T08:21:31.084Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-28T08:23:56.201Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-28T08:26:59.274Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-28T08:27:29.359Z"
   },
   {
    "duration": 37,
    "start_time": "2024-07-28T08:27:30.941Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-28T08:27:31.258Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-28T08:27:31.737Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-28T08:27:33.001Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-28T08:27:35.677Z"
   },
   {
    "duration": 55,
    "start_time": "2024-07-28T08:28:05.414Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-28T08:30:06.448Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-28T08:30:10.772Z"
   },
   {
    "duration": 37,
    "start_time": "2024-07-28T08:30:11.163Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-28T08:30:11.343Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-28T08:30:11.537Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-28T08:30:13.190Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-28T08:30:14.695Z"
   },
   {
    "duration": 60,
    "start_time": "2024-07-28T08:30:16.824Z"
   },
   {
    "duration": 53,
    "start_time": "2024-07-28T08:33:28.007Z"
   },
   {
    "duration": 76,
    "start_time": "2024-07-28T08:37:25.995Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-28T08:38:22.743Z"
   },
   {
    "duration": 36,
    "start_time": "2024-07-28T08:38:23.148Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-28T08:38:23.487Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-28T08:38:23.795Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-28T08:38:24.144Z"
   },
   {
    "duration": 77,
    "start_time": "2024-07-28T08:38:36.967Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-28T08:39:34.077Z"
   },
   {
    "duration": 71,
    "start_time": "2024-07-28T08:39:35.478Z"
   },
   {
    "duration": 219,
    "start_time": "2024-07-28T08:39:44.768Z"
   },
   {
    "duration": 1428,
    "start_time": "2024-07-28T08:39:51.114Z"
   },
   {
    "duration": 1387,
    "start_time": "2024-07-28T08:39:58.233Z"
   },
   {
    "duration": 1394,
    "start_time": "2024-07-28T08:40:08.804Z"
   },
   {
    "duration": 269,
    "start_time": "2024-07-28T08:42:17.890Z"
   },
   {
    "duration": 282,
    "start_time": "2024-07-28T08:42:28.153Z"
   },
   {
    "duration": 1221,
    "start_time": "2024-07-31T01:43:36.329Z"
   },
   {
    "duration": 61,
    "start_time": "2024-07-31T01:43:37.554Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-31T01:43:37.618Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-31T01:43:37.639Z"
   },
   {
    "duration": 52,
    "start_time": "2024-07-31T01:43:37.673Z"
   },
   {
    "duration": 90,
    "start_time": "2024-07-31T01:43:37.728Z"
   },
   {
    "duration": 238,
    "start_time": "2024-07-31T01:43:37.821Z"
   },
   {
    "duration": 1805,
    "start_time": "2024-07-31T01:43:38.062Z"
   },
   {
    "duration": 0,
    "start_time": "2024-07-31T01:43:39.870Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-31T01:44:07.098Z"
   },
   {
    "duration": 1445,
    "start_time": "2024-07-31T01:44:11.920Z"
   },
   {
    "duration": 275,
    "start_time": "2024-07-31T01:44:22.764Z"
   },
   {
    "duration": 202,
    "start_time": "2024-07-31T01:49:56.043Z"
   },
   {
    "duration": 1432,
    "start_time": "2024-07-31T01:49:57.108Z"
   },
   {
    "duration": 284,
    "start_time": "2024-07-31T01:49:59.767Z"
   },
   {
    "duration": 1505,
    "start_time": "2024-07-31T02:00:27.517Z"
   },
   {
    "duration": 1414,
    "start_time": "2024-07-31T02:00:38.738Z"
   },
   {
    "duration": 1464,
    "start_time": "2024-07-31T02:00:50.029Z"
   },
   {
    "duration": 1457,
    "start_time": "2024-07-31T02:00:55.499Z"
   },
   {
    "duration": 1424,
    "start_time": "2024-07-31T02:01:17.717Z"
   },
   {
    "duration": 361,
    "start_time": "2024-07-31T02:01:27.659Z"
   },
   {
    "duration": 274,
    "start_time": "2024-07-31T02:01:38.961Z"
   },
   {
    "duration": 1424,
    "start_time": "2024-07-31T02:01:48.994Z"
   },
   {
    "duration": 268,
    "start_time": "2024-07-31T02:01:58.861Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-31T02:02:36.654Z"
   },
   {
    "duration": 38,
    "start_time": "2024-07-31T02:02:37.266Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-31T02:02:38.328Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-31T02:02:40.427Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-31T02:02:43.521Z"
   },
   {
    "duration": 69,
    "start_time": "2024-07-31T02:02:46.909Z"
   },
   {
    "duration": 210,
    "start_time": "2024-07-31T02:02:49.486Z"
   },
   {
    "duration": 266,
    "start_time": "2024-07-31T02:02:51.882Z"
   },
   {
    "duration": 1439,
    "start_time": "2024-07-31T02:02:54.704Z"
   },
   {
    "duration": 1215,
    "start_time": "2024-08-01T21:21:13.851Z"
   },
   {
    "duration": 50,
    "start_time": "2024-08-01T21:21:18.747Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-01T21:21:19.922Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-01T21:21:22.430Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-01T21:21:26.094Z"
   },
   {
    "duration": 83,
    "start_time": "2024-08-01T21:21:41.217Z"
   },
   {
    "duration": 416,
    "start_time": "2024-08-01T21:22:14.683Z"
   },
   {
    "duration": 223,
    "start_time": "2024-08-01T21:22:25.608Z"
   },
   {
    "duration": 271,
    "start_time": "2024-08-01T21:22:30.470Z"
   },
   {
    "duration": 272,
    "start_time": "2024-08-01T21:31:33.534Z"
   },
   {
    "duration": 786,
    "start_time": "2024-08-01T21:37:54.031Z"
   },
   {
    "duration": 286,
    "start_time": "2024-08-01T21:38:45.314Z"
   },
   {
    "duration": 541,
    "start_time": "2024-08-01T21:38:54.734Z"
   },
   {
    "duration": 269,
    "start_time": "2024-08-01T21:39:30.267Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T21:39:40.141Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-01T21:39:40.630Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-01T21:39:41.720Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-01T21:39:43.351Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-01T21:39:46.711Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-01T21:47:02.558Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-01T21:47:12.516Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-01T21:47:53.919Z"
   },
   {
    "duration": 18,
    "start_time": "2024-08-01T21:48:24.363Z"
   },
   {
    "duration": 861,
    "start_time": "2024-08-01T21:51:29.334Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T21:51:33.254Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-01T21:51:33.560Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-01T21:51:34.087Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-01T21:51:34.761Z"
   },
   {
    "duration": 22,
    "start_time": "2024-08-01T21:51:39.251Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-01T21:51:46.130Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-01T21:51:50.423Z"
   },
   {
    "duration": 59,
    "start_time": "2024-08-01T21:52:31.861Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-01T22:04:25.545Z"
   },
   {
    "duration": 44,
    "start_time": "2024-08-01T22:04:26.614Z"
   },
   {
    "duration": 70,
    "start_time": "2024-08-01T22:06:33.695Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T22:07:33.223Z"
   },
   {
    "duration": 91,
    "start_time": "2024-08-01T22:09:02.339Z"
   },
   {
    "duration": 80,
    "start_time": "2024-08-01T22:10:19.758Z"
   },
   {
    "duration": 87,
    "start_time": "2024-08-01T22:11:29.626Z"
   },
   {
    "duration": 101,
    "start_time": "2024-08-01T22:12:09.951Z"
   },
   {
    "duration": 84,
    "start_time": "2024-08-01T22:12:28.689Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-01T22:13:18.450Z"
   },
   {
    "duration": 191,
    "start_time": "2024-08-01T22:13:42.203Z"
   },
   {
    "duration": 208,
    "start_time": "2024-08-01T22:31:11.983Z"
   },
   {
    "duration": 145,
    "start_time": "2024-08-01T22:33:25.947Z"
   },
   {
    "duration": 3938,
    "start_time": "2024-08-01T22:42:12.711Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-01T22:43:18.779Z"
   },
   {
    "duration": 210,
    "start_time": "2024-08-01T22:43:25.781Z"
   },
   {
    "duration": 87,
    "start_time": "2024-08-01T22:49:41.787Z"
   },
   {
    "duration": 89,
    "start_time": "2024-08-01T23:00:47.770Z"
   },
   {
    "duration": 98,
    "start_time": "2024-08-01T23:03:42.278Z"
   },
   {
    "duration": 209,
    "start_time": "2024-08-01T23:05:39.682Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-01T23:06:17.478Z"
   },
   {
    "duration": 98,
    "start_time": "2024-08-01T23:06:27.735Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-01T23:20:00.190Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-01T23:20:24.065Z"
   },
   {
    "duration": 5004,
    "start_time": "2024-08-02T14:47:05.132Z"
   },
   {
    "duration": 49,
    "start_time": "2024-08-02T14:47:11.614Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-02T14:47:14.325Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T14:47:17.225Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-02T14:47:21.137Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-02T14:47:25.405Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T14:47:44.649Z"
   },
   {
    "duration": 172,
    "start_time": "2024-08-02T14:49:07.737Z"
   },
   {
    "duration": 132,
    "start_time": "2024-08-02T14:50:03.600Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T14:50:35.837Z"
   },
   {
    "duration": 482,
    "start_time": "2024-08-02T15:16:38.318Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-02T15:17:07.809Z"
   },
   {
    "duration": 51,
    "start_time": "2024-08-02T15:17:12.344Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T15:17:34.672Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-02T15:17:37.742Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T15:17:45.969Z"
   },
   {
    "duration": 99,
    "start_time": "2024-08-02T15:19:47.033Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T15:20:53.972Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T15:29:45.710Z"
   },
   {
    "duration": 65,
    "start_time": "2024-08-02T15:29:46.348Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T15:29:47.764Z"
   },
   {
    "duration": 96,
    "start_time": "2024-08-02T15:29:49.373Z"
   },
   {
    "duration": 116,
    "start_time": "2024-08-02T15:34:39.946Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-02T15:43:51.256Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-02T15:43:56.700Z"
   },
   {
    "duration": 78,
    "start_time": "2024-08-02T15:45:30.533Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T15:45:46.108Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-02T15:51:41.175Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-02T15:53:01.708Z"
   },
   {
    "duration": 86,
    "start_time": "2024-08-02T15:53:39.695Z"
   },
   {
    "duration": 73,
    "start_time": "2024-08-02T15:54:04.490Z"
   },
   {
    "duration": 71,
    "start_time": "2024-08-02T15:55:45.087Z"
   },
   {
    "duration": 267,
    "start_time": "2024-08-02T15:55:50.255Z"
   },
   {
    "duration": 2609,
    "start_time": "2024-08-02T15:55:56.571Z"
   },
   {
    "duration": 57,
    "start_time": "2024-08-02T15:56:06.208Z"
   },
   {
    "duration": 79,
    "start_time": "2024-08-02T15:56:13.770Z"
   },
   {
    "duration": 108,
    "start_time": "2024-08-02T15:56:18.646Z"
   },
   {
    "duration": 108,
    "start_time": "2024-08-02T15:56:28.830Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T15:56:34.523Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T15:56:37.318Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T15:56:41.158Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T15:56:47.075Z"
   },
   {
    "duration": 49,
    "start_time": "2024-08-02T15:56:49.995Z"
   },
   {
    "duration": 60,
    "start_time": "2024-08-02T15:56:54.203Z"
   },
   {
    "duration": 65,
    "start_time": "2024-08-02T15:56:57.151Z"
   },
   {
    "duration": 64,
    "start_time": "2024-08-02T15:57:00.799Z"
   },
   {
    "duration": 70,
    "start_time": "2024-08-02T15:57:04.839Z"
   },
   {
    "duration": 86,
    "start_time": "2024-08-02T15:57:09.022Z"
   },
   {
    "duration": 80,
    "start_time": "2024-08-02T15:57:12.874Z"
   },
   {
    "duration": 124,
    "start_time": "2024-08-02T15:57:17.103Z"
   },
   {
    "duration": 1124,
    "start_time": "2024-08-02T15:57:20.053Z"
   },
   {
    "duration": 80,
    "start_time": "2024-08-02T15:57:29.842Z"
   },
   {
    "duration": 85,
    "start_time": "2024-08-02T15:57:46.827Z"
   },
   {
    "duration": 41,
    "start_time": "2024-08-02T15:57:50.490Z"
   },
   {
    "duration": 90,
    "start_time": "2024-08-02T15:57:54.654Z"
   },
   {
    "duration": 553,
    "start_time": "2024-08-02T15:58:04.154Z"
   },
   {
    "duration": 83,
    "start_time": "2024-08-02T15:58:13.381Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T15:58:17.194Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T15:58:22.059Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T15:58:35.035Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T15:58:38.206Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T15:58:42.354Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T15:58:48.280Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T15:59:35.554Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-02T15:59:40.246Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T15:59:43.196Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-02T15:59:46.982Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-02T15:59:50.276Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-02T15:59:52.430Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T15:59:54.675Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-02T15:59:56.662Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T16:00:01.132Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-02T16:00:03.936Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-02T16:00:09.435Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T16:00:13.582Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T16:00:17.031Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-02T16:00:20.854Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T16:00:24.211Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T16:00:29.387Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T16:00:33.862Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T16:00:36.525Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T16:00:39.966Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T16:00:42.681Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T16:00:45.532Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T16:00:48.030Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T16:00:58.995Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T16:01:11.206Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T16:01:28.434Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T16:01:34.578Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T16:01:37.647Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T16:01:39.654Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T16:01:47.065Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T16:01:49.544Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T16:01:52.455Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T16:02:01.583Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-02T16:02:03.927Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T16:02:08.884Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T16:02:16.186Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T16:02:20.922Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T16:02:28.646Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T16:02:31.594Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T16:02:36.128Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T16:02:40.757Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-02T16:02:48.495Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T16:02:54.394Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T16:21:33.172Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T16:24:51.462Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:24:55.157Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-02T16:25:03.126Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:25:05.807Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:25:07.786Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-02T16:25:09.682Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:25:11.655Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:25:14.523Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:25:16.970Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T16:25:19.832Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:25:22.745Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:25:30.061Z"
   },
   {
    "duration": 130,
    "start_time": "2024-08-02T16:26:46.443Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T16:26:55.383Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:26:59.671Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:27:03.958Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:27:07.527Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T16:27:11.603Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T16:27:13.635Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:27:15.502Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:27:26.938Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T16:27:29.958Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:27:32.050Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:27:34.253Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:27:46.983Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T16:27:55.503Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:27:58.579Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T16:46:25.294Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T16:46:31.441Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-02T16:47:03.538Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:47:09.178Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:47:11.794Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:47:14.690Z"
   },
   {
    "duration": 18,
    "start_time": "2024-08-02T16:47:17.339Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-02T16:47:20.574Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:47:23.594Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-02T16:47:26.462Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T16:47:29.586Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:47:35.010Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:47:37.294Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:47:39.807Z"
   },
   {
    "duration": 18,
    "start_time": "2024-08-02T16:47:43.914Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:47:46.662Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:47:53.781Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T16:47:58.936Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:48:01.610Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:48:11.542Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T16:48:36.622Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:48:39.714Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:48:45.074Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:48:48.689Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:48:50.618Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:48:53.385Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:48:55.935Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:48:58.448Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T16:49:01.518Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:49:04.256Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:49:08.535Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-02T16:49:15.519Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:49:18.473Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-02T16:49:24.471Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:49:26.755Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:49:29.282Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T16:49:31.954Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T16:49:37.762Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-02T16:49:42.614Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T16:49:46.083Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T16:49:49.874Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T16:49:55.494Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T16:50:05.270Z"
   },
   {
    "duration": 114,
    "start_time": "2024-08-02T16:53:14.855Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T16:54:24.547Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-02T16:54:27.397Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-02T16:54:42.061Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-02T16:54:49.246Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T17:01:58.241Z"
   },
   {
    "duration": 153,
    "start_time": "2024-08-02T17:04:20.696Z"
   },
   {
    "duration": 1066,
    "start_time": "2024-08-02T17:04:41.672Z"
   },
   {
    "duration": 277,
    "start_time": "2024-08-02T17:08:57.709Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-02T17:10:36.689Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-02T17:11:03.665Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-02T17:11:09.410Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-02T17:11:17.289Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-02T17:11:19.313Z"
   },
   {
    "duration": 26,
    "start_time": "2024-08-02T17:11:21.306Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:11:23.150Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T17:11:26.354Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:11:28.977Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-02T17:11:32.984Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T17:11:42.182Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T17:11:45.365Z"
   },
   {
    "duration": 44,
    "start_time": "2024-08-02T17:11:47.919Z"
   },
   {
    "duration": 51,
    "start_time": "2024-08-02T17:11:51.409Z"
   },
   {
    "duration": 48,
    "start_time": "2024-08-02T17:11:56.141Z"
   },
   {
    "duration": 53,
    "start_time": "2024-08-02T17:11:58.503Z"
   },
   {
    "duration": 51,
    "start_time": "2024-08-02T17:12:02.183Z"
   },
   {
    "duration": 56,
    "start_time": "2024-08-02T17:12:04.901Z"
   },
   {
    "duration": 53,
    "start_time": "2024-08-02T17:12:07.493Z"
   },
   {
    "duration": 53,
    "start_time": "2024-08-02T17:12:10.290Z"
   },
   {
    "duration": 55,
    "start_time": "2024-08-02T17:12:13.048Z"
   },
   {
    "duration": 54,
    "start_time": "2024-08-02T17:12:15.736Z"
   },
   {
    "duration": 56,
    "start_time": "2024-08-02T17:12:19.353Z"
   },
   {
    "duration": 55,
    "start_time": "2024-08-02T17:12:22.409Z"
   },
   {
    "duration": 55,
    "start_time": "2024-08-02T17:12:25.442Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T17:12:29.805Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:12:32.425Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T17:12:34.725Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-02T17:12:36.502Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T17:12:41.805Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-02T17:12:44.865Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-02T17:12:48.714Z"
   },
   {
    "duration": 26,
    "start_time": "2024-08-02T17:12:50.966Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:12:53.103Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T17:12:55.000Z"
   },
   {
    "duration": 269,
    "start_time": "2024-08-02T17:13:32.834Z"
   },
   {
    "duration": 282,
    "start_time": "2024-08-02T17:13:53.762Z"
   },
   {
    "duration": 2219,
    "start_time": "2024-08-02T17:14:04.278Z"
   },
   {
    "duration": 1203,
    "start_time": "2024-08-02T17:14:21.467Z"
   },
   {
    "duration": 47,
    "start_time": "2024-08-02T17:17:30.257Z"
   },
   {
    "duration": 49,
    "start_time": "2024-08-02T17:17:40.909Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-02T17:17:42.835Z"
   },
   {
    "duration": 61,
    "start_time": "2024-08-02T17:17:46.142Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T17:17:47.995Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-02T17:17:52.043Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T17:17:54.734Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T17:18:52.731Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T17:19:03.225Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T17:19:05.542Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T17:19:09.649Z"
   },
   {
    "duration": 49,
    "start_time": "2024-08-02T17:19:11.779Z"
   },
   {
    "duration": 51,
    "start_time": "2024-08-02T17:19:13.793Z"
   },
   {
    "duration": 205,
    "start_time": "2024-08-02T17:19:17.714Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T17:19:28.949Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-02T17:19:31.725Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T17:19:33.806Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T17:19:36.045Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-02T17:19:39.737Z"
   },
   {
    "duration": 45,
    "start_time": "2024-08-02T17:19:41.389Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-02T17:19:43.479Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-02T17:19:45.278Z"
   },
   {
    "duration": 54,
    "start_time": "2024-08-02T17:19:47.445Z"
   },
   {
    "duration": 58,
    "start_time": "2024-08-02T17:19:49.921Z"
   },
   {
    "duration": 58,
    "start_time": "2024-08-02T17:19:52.969Z"
   },
   {
    "duration": 60,
    "start_time": "2024-08-02T17:19:55.669Z"
   },
   {
    "duration": 63,
    "start_time": "2024-08-02T17:19:57.697Z"
   },
   {
    "duration": 66,
    "start_time": "2024-08-02T17:20:01.001Z"
   },
   {
    "duration": 74,
    "start_time": "2024-08-02T17:20:03.758Z"
   },
   {
    "duration": 70,
    "start_time": "2024-08-02T17:20:06.605Z"
   },
   {
    "duration": 73,
    "start_time": "2024-08-02T17:20:11.523Z"
   },
   {
    "duration": 83,
    "start_time": "2024-08-02T17:20:15.233Z"
   },
   {
    "duration": 167,
    "start_time": "2024-08-02T17:20:19.142Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T17:20:22.551Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T17:20:30.277Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-02T17:22:49.318Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T17:23:22.695Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-02T17:23:28.454Z"
   },
   {
    "duration": 26,
    "start_time": "2024-08-02T17:23:30.862Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-02T17:23:33.854Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-02T17:23:35.757Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:23:38.258Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:23:40.081Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:23:45.669Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:23:50.721Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:23:54.134Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:23:59.266Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:24:08.283Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:24:11.387Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:24:13.689Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:24:19.533Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:24:23.533Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:24:26.561Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:24:29.622Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T17:24:33.581Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-02T17:24:38.910Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:24:43.569Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:24:52.767Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:25:00.478Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:25:04.030Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T17:25:07.482Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:25:10.995Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:25:15.173Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:25:19.006Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-02T17:25:33.298Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-02T17:25:36.104Z"
   },
   {
    "duration": 26,
    "start_time": "2024-08-02T17:25:37.897Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T17:25:40.122Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:25:42.111Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:25:46.876Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T17:25:50.657Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T17:25:55.757Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T17:25:59.249Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T17:26:02.253Z"
   },
   {
    "duration": 41,
    "start_time": "2024-08-02T17:26:04.833Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-02T17:26:10.478Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-02T17:26:13.226Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-02T17:26:15.753Z"
   },
   {
    "duration": 44,
    "start_time": "2024-08-02T17:26:19.613Z"
   },
   {
    "duration": 45,
    "start_time": "2024-08-02T17:26:22.877Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:26:28.901Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-02T17:26:47.105Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-02T17:26:50.570Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T17:26:53.997Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-02T17:26:56.353Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T17:26:58.743Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-02T17:27:00.902Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T17:27:03.525Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T17:27:06.854Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T17:27:10.753Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-02T17:27:13.706Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T17:27:15.641Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-02T17:27:38.213Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-02T17:27:42.106Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-02T17:30:07.533Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:30:17.657Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-02T17:30:24.706Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:30:28.529Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:30:31.466Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:30:33.929Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:30:36.098Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:30:38.417Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:30:42.365Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:30:44.759Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:30:46.625Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:30:49.217Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T17:31:11.609Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:31:15.153Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:31:23.013Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:31:32.954Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:31:40.308Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:31:45.165Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:31:50.237Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:31:53.422Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:31:56.330Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:31:59.913Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:32:09.178Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:32:11.227Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T17:32:18.305Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T17:32:22.085Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:32:26.959Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:32:30.093Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:32:33.213Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:17.703Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:24.977Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T17:33:28.245Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:30.154Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:32.194Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T17:33:33.879Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:36.053Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:33:37.761Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-02T17:33:39.529Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:43.518Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:33:45.165Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:33:46.862Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:33:49.524Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:33:52.791Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:33:56.457Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T17:34:43.756Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:34:47.481Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:34:49.908Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:34:54.047Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:34:56.241Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:34:57.945Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T17:35:00.486Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T17:35:02.437Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-02T17:35:05.138Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T17:35:14.917Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T17:35:18.473Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-02T17:35:49.553Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-02T17:36:51.981Z"
   },
   {
    "duration": 5584,
    "start_time": "2024-08-02T23:17:16.567Z"
   },
   {
    "duration": 67,
    "start_time": "2024-08-02T23:17:40.288Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-02T23:17:55.315Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-02T23:18:20.938Z"
   },
   {
    "duration": 47,
    "start_time": "2024-08-02T23:19:00.499Z"
   },
   {
    "duration": 57,
    "start_time": "2024-08-02T23:20:02.624Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-02T23:22:38.983Z"
   },
   {
    "duration": 499,
    "start_time": "2024-08-02T23:28:25.207Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T23:28:44.443Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T23:28:47.076Z"
   },
   {
    "duration": 96,
    "start_time": "2024-08-02T23:28:47.997Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-02T23:38:27.442Z"
   },
   {
    "duration": 178,
    "start_time": "2024-08-02T23:39:24.717Z"
   },
   {
    "duration": 191,
    "start_time": "2024-08-02T23:39:34.701Z"
   },
   {
    "duration": 106,
    "start_time": "2024-08-02T23:39:54.886Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T23:40:16.232Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-02T23:40:16.579Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-02T23:40:17.078Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-02T23:40:17.484Z"
   },
   {
    "duration": 22,
    "start_time": "2024-08-02T23:40:18.608Z"
   },
   {
    "duration": 56,
    "start_time": "2024-08-02T23:40:19.184Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T23:40:21.530Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-02T23:40:24.049Z"
   },
   {
    "duration": 81,
    "start_time": "2024-08-02T23:40:25.620Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T23:44:05.439Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-02T23:52:09.243Z"
   },
   {
    "duration": 120,
    "start_time": "2024-08-02T23:56:32.768Z"
   },
   {
    "duration": 54,
    "start_time": "2024-08-02T23:57:43.875Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-02T23:57:51.177Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T23:57:57.760Z"
   },
   {
    "duration": 87,
    "start_time": "2024-08-03T00:02:56.711Z"
   },
   {
    "duration": 45,
    "start_time": "2024-08-03T00:10:54.962Z"
   },
   {
    "duration": 114,
    "start_time": "2024-08-03T00:24:23.985Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-03T00:26:02.115Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-03T00:26:34.074Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-03T00:29:00.036Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-03T00:29:31.668Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-03T00:30:04.392Z"
   },
   {
    "duration": 176,
    "start_time": "2024-08-03T00:30:08.827Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-03T00:33:39.909Z"
   },
   {
    "duration": 184,
    "start_time": "2024-08-03T00:33:44.729Z"
   },
   {
    "duration": 249,
    "start_time": "2024-08-03T00:36:43.256Z"
   },
   {
    "duration": 368,
    "start_time": "2024-08-03T00:39:47.923Z"
   },
   {
    "duration": 322,
    "start_time": "2024-08-03T00:40:05.576Z"
   },
   {
    "duration": 324,
    "start_time": "2024-08-03T00:40:26.576Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-03T00:43:54.110Z"
   },
   {
    "duration": 301,
    "start_time": "2024-08-03T00:44:07.800Z"
   },
   {
    "duration": 9985,
    "start_time": "2024-08-03T00:45:10.220Z"
   },
   {
    "duration": 10964,
    "start_time": "2024-08-03T00:47:31.147Z"
   },
   {
    "duration": 1049,
    "start_time": "2024-08-03T00:49:12.156Z"
   },
   {
    "duration": 92,
    "start_time": "2024-08-03T00:52:19.620Z"
   },
   {
    "duration": 1073,
    "start_time": "2024-08-03T00:53:35.921Z"
   },
   {
    "duration": 132,
    "start_time": "2024-08-03T00:55:16.961Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-03T00:55:59.231Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-03T00:56:19.248Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-03T00:56:49.543Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-03T00:59:50.298Z"
   },
   {
    "duration": 28,
    "start_time": "2024-08-03T01:00:11.587Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-03T01:00:28.031Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-03T01:00:39.816Z"
   },
   {
    "duration": 66,
    "start_time": "2024-08-03T01:02:02.253Z"
   },
   {
    "duration": 174,
    "start_time": "2024-08-03T01:02:05.778Z"
   },
   {
    "duration": 983,
    "start_time": "2024-08-03T01:02:45.917Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-03T01:03:36.461Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-03T01:04:04.237Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-03T01:04:08.637Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-03T01:04:17.088Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-03T01:04:30.097Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-03T01:04:37.911Z"
   },
   {
    "duration": 1983,
    "start_time": "2024-08-03T01:05:20.123Z"
   },
   {
    "duration": 2028,
    "start_time": "2024-08-03T01:05:36.967Z"
   },
   {
    "duration": 4275,
    "start_time": "2024-08-03T01:08:47.232Z"
   },
   {
    "duration": 2061,
    "start_time": "2024-08-03T01:09:13.332Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-03T01:10:06.990Z"
   },
   {
    "duration": 118,
    "start_time": "2024-08-03T01:11:50.373Z"
   },
   {
    "duration": 2806,
    "start_time": "2024-08-03T01:12:46.294Z"
   },
   {
    "duration": 1986,
    "start_time": "2024-08-03T01:14:08.525Z"
   },
   {
    "duration": 88,
    "start_time": "2024-08-03T01:14:41.208Z"
   },
   {
    "duration": 5161,
    "start_time": "2024-08-05T19:57:56.843Z"
   },
   {
    "duration": 59,
    "start_time": "2024-08-05T19:58:15.527Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-05T19:58:16.383Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-05T19:58:17.127Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-05T19:58:18.352Z"
   },
   {
    "duration": 54,
    "start_time": "2024-08-05T19:58:18.891Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T19:58:19.432Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-05T19:58:21.074Z"
   },
   {
    "duration": 103,
    "start_time": "2024-08-05T19:58:21.880Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T19:58:23.359Z"
   },
   {
    "duration": 117,
    "start_time": "2024-08-05T19:58:27.155Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-05T19:58:29.690Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T19:58:31.719Z"
   },
   {
    "duration": 1124,
    "start_time": "2024-08-05T19:58:32.646Z"
   },
   {
    "duration": 59,
    "start_time": "2024-08-05T19:58:37.130Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T19:58:38.523Z"
   },
   {
    "duration": 1970,
    "start_time": "2024-08-05T19:58:39.599Z"
   },
   {
    "duration": 73,
    "start_time": "2024-08-05T19:58:43.201Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-05T19:58:47.351Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-05T19:58:48.520Z"
   },
   {
    "duration": 117,
    "start_time": "2024-08-05T19:58:59.396Z"
   },
   {
    "duration": 1207,
    "start_time": "2024-08-05T19:59:13.943Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-05T19:59:18.656Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-05T19:59:20.792Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-05T19:59:22.849Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-05T19:59:25.819Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-05T19:59:29.367Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-05T19:59:31.432Z"
   },
   {
    "duration": 1052,
    "start_time": "2024-08-05T20:14:18.729Z"
   },
   {
    "duration": 1063,
    "start_time": "2024-08-05T20:14:49.211Z"
   },
   {
    "duration": 1116,
    "start_time": "2024-08-05T20:15:27.969Z"
   },
   {
    "duration": 2202,
    "start_time": "2024-08-05T20:21:23.476Z"
   },
   {
    "duration": 2234,
    "start_time": "2024-08-05T20:22:03.451Z"
   },
   {
    "duration": 50,
    "start_time": "2024-08-05T20:23:39.041Z"
   },
   {
    "duration": 233,
    "start_time": "2024-08-05T20:25:42.348Z"
   },
   {
    "duration": 181,
    "start_time": "2024-08-05T21:09:25.492Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-05T21:34:39.783Z"
   },
   {
    "duration": 79,
    "start_time": "2024-08-05T21:36:16.581Z"
   },
   {
    "duration": 66,
    "start_time": "2024-08-05T21:37:45.494Z"
   },
   {
    "duration": 75,
    "start_time": "2024-08-05T21:38:50.017Z"
   },
   {
    "duration": 1210,
    "start_time": "2024-08-05T21:46:19.349Z"
   },
   {
    "duration": 1195,
    "start_time": "2024-08-05T21:48:02.260Z"
   },
   {
    "duration": 1214,
    "start_time": "2024-08-05T21:57:15.373Z"
   },
   {
    "duration": 753,
    "start_time": "2024-08-05T22:00:35.540Z"
   },
   {
    "duration": 77,
    "start_time": "2024-08-05T22:00:54.872Z"
   },
   {
    "duration": 111,
    "start_time": "2024-08-05T22:03:53.018Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T22:08:06.232Z"
   },
   {
    "duration": 117,
    "start_time": "2024-08-05T22:08:18.261Z"
   },
   {
    "duration": 41,
    "start_time": "2024-08-05T22:08:32.320Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-05T22:09:04.882Z"
   },
   {
    "duration": 400,
    "start_time": "2024-08-05T22:18:47.540Z"
   },
   {
    "duration": 406,
    "start_time": "2024-08-05T22:20:49.455Z"
   },
   {
    "duration": 409,
    "start_time": "2024-08-05T22:30:34.385Z"
   },
   {
    "duration": 437,
    "start_time": "2024-08-05T22:31:10.835Z"
   },
   {
    "duration": 403,
    "start_time": "2024-08-05T22:31:34.591Z"
   },
   {
    "duration": 424,
    "start_time": "2024-08-05T22:34:06.483Z"
   },
   {
    "duration": 689,
    "start_time": "2024-08-05T22:36:15.531Z"
   },
   {
    "duration": 402,
    "start_time": "2024-08-05T22:36:44.203Z"
   },
   {
    "duration": 699,
    "start_time": "2024-08-05T22:36:47.844Z"
   },
   {
    "duration": 663,
    "start_time": "2024-08-05T22:38:28.563Z"
   },
   {
    "duration": 632,
    "start_time": "2024-08-05T22:38:36.339Z"
   },
   {
    "duration": 650,
    "start_time": "2024-08-05T22:38:46.159Z"
   },
   {
    "duration": 620,
    "start_time": "2024-08-05T22:38:51.748Z"
   },
   {
    "duration": 672,
    "start_time": "2024-08-05T22:38:57.403Z"
   },
   {
    "duration": 652,
    "start_time": "2024-08-05T22:39:01.855Z"
   },
   {
    "duration": 686,
    "start_time": "2024-08-05T22:44:27.192Z"
   },
   {
    "duration": 410,
    "start_time": "2024-08-05T22:46:05.250Z"
   },
   {
    "duration": 428,
    "start_time": "2024-08-05T22:46:29.600Z"
   },
   {
    "duration": 411,
    "start_time": "2024-08-05T22:46:36.003Z"
   },
   {
    "duration": 202,
    "start_time": "2024-08-05T22:47:01.514Z"
   },
   {
    "duration": 234,
    "start_time": "2024-08-05T22:47:07.471Z"
   },
   {
    "duration": 256,
    "start_time": "2024-08-05T22:49:48.067Z"
   },
   {
    "duration": 251,
    "start_time": "2024-08-05T22:50:54.643Z"
   },
   {
    "duration": 2764,
    "start_time": "2024-08-05T22:51:14.030Z"
   },
   {
    "duration": 1427,
    "start_time": "2024-08-05T22:51:42.647Z"
   },
   {
    "duration": 2841,
    "start_time": "2024-08-05T22:51:57.865Z"
   },
   {
    "duration": 2770,
    "start_time": "2024-08-05T22:52:16.741Z"
   },
   {
    "duration": 2980,
    "start_time": "2024-08-05T22:52:27.552Z"
   },
   {
    "duration": 2782,
    "start_time": "2024-08-05T22:53:03.931Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T22:53:16.444Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-05T22:53:18.024Z"
   },
   {
    "duration": 2839,
    "start_time": "2024-08-05T22:58:15.229Z"
   },
   {
    "duration": 2631,
    "start_time": "2024-08-05T22:58:28.090Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T23:04:43.065Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-05T23:04:43.917Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-05T23:04:44.517Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-05T23:04:44.810Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-05T23:04:44.990Z"
   },
   {
    "duration": 53,
    "start_time": "2024-08-05T23:04:45.153Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T23:04:45.320Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-05T23:04:45.793Z"
   },
   {
    "duration": 110,
    "start_time": "2024-08-05T23:04:45.964Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-05T23:04:46.297Z"
   },
   {
    "duration": 64,
    "start_time": "2024-08-05T23:04:46.612Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-05T23:04:46.947Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T23:04:47.558Z"
   },
   {
    "duration": 1119,
    "start_time": "2024-08-05T23:04:47.764Z"
   },
   {
    "duration": 283,
    "start_time": "2024-08-05T23:04:48.888Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T23:04:49.905Z"
   },
   {
    "duration": 2229,
    "start_time": "2024-08-05T23:04:50.157Z"
   },
   {
    "duration": 196,
    "start_time": "2024-08-05T23:04:52.389Z"
   },
   {
    "duration": 388,
    "start_time": "2024-08-05T23:04:52.588Z"
   },
   {
    "duration": 308,
    "start_time": "2024-08-05T23:04:52.980Z"
   },
   {
    "duration": 119,
    "start_time": "2024-08-05T23:04:53.367Z"
   },
   {
    "duration": 87,
    "start_time": "2024-08-05T23:04:53.489Z"
   },
   {
    "duration": 1469,
    "start_time": "2024-08-05T23:05:12.855Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-05T23:05:14.329Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-05T23:05:14.383Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-05T23:05:14.403Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-05T23:05:14.467Z"
   },
   {
    "duration": 53,
    "start_time": "2024-08-05T23:05:14.493Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-05T23:05:14.569Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-05T23:05:14.580Z"
   },
   {
    "duration": 175,
    "start_time": "2024-08-05T23:05:14.593Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T23:05:14.771Z"
   },
   {
    "duration": 197,
    "start_time": "2024-08-05T23:05:14.785Z"
   },
   {
    "duration": 94,
    "start_time": "2024-08-05T23:05:14.986Z"
   },
   {
    "duration": 80,
    "start_time": "2024-08-05T23:05:15.090Z"
   },
   {
    "duration": 1111,
    "start_time": "2024-08-05T23:05:15.178Z"
   },
   {
    "duration": 287,
    "start_time": "2024-08-05T23:05:16.292Z"
   },
   {
    "duration": 85,
    "start_time": "2024-08-05T23:05:16.588Z"
   },
   {
    "duration": 2501,
    "start_time": "2024-08-05T23:05:16.683Z"
   },
   {
    "duration": 201,
    "start_time": "2024-08-05T23:05:19.267Z"
   },
   {
    "duration": 400,
    "start_time": "2024-08-05T23:05:19.472Z"
   },
   {
    "duration": 391,
    "start_time": "2024-08-05T23:05:19.880Z"
   },
   {
    "duration": 119,
    "start_time": "2024-08-05T23:05:20.279Z"
   },
   {
    "duration": 92,
    "start_time": "2024-08-05T23:05:20.401Z"
   },
   {
    "duration": 1247,
    "start_time": "2024-08-05T23:05:20.497Z"
   },
   {
    "duration": 55,
    "start_time": "2024-08-05T23:05:21.747Z"
   },
   {
    "duration": 1286,
    "start_time": "2024-08-05T23:05:21.806Z"
   },
   {
    "duration": 435,
    "start_time": "2024-08-05T23:05:23.095Z"
   },
   {
    "duration": 736,
    "start_time": "2024-08-05T23:05:23.533Z"
   },
   {
    "duration": 529,
    "start_time": "2024-08-05T23:05:24.272Z"
   },
   {
    "duration": 0,
    "start_time": "2024-08-05T23:05:24.804Z"
   },
   {
    "duration": 0,
    "start_time": "2024-08-05T23:05:24.806Z"
   },
   {
    "duration": 2633,
    "start_time": "2024-08-05T23:05:41.445Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-05T23:06:35.026Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-05T23:10:51.032Z"
   },
   {
    "duration": 449,
    "start_time": "2024-08-05T23:26:51.396Z"
   },
   {
    "duration": 712,
    "start_time": "2024-08-05T23:28:30.544Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-05T23:28:55.953Z"
   },
   {
    "duration": 686,
    "start_time": "2024-08-05T23:29:15.212Z"
   },
   {
    "duration": 707,
    "start_time": "2024-08-05T23:29:27.383Z"
   },
   {
    "duration": 1408,
    "start_time": "2024-08-05T23:55:04.445Z"
   },
   {
    "duration": 50,
    "start_time": "2024-08-05T23:55:05.856Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-05T23:55:05.912Z"
   },
   {
    "duration": 58,
    "start_time": "2024-08-05T23:55:05.941Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-05T23:55:06.002Z"
   },
   {
    "duration": 83,
    "start_time": "2024-08-05T23:55:06.028Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-05T23:55:06.114Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T23:55:06.123Z"
   },
   {
    "duration": 103,
    "start_time": "2024-08-05T23:55:06.167Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T23:55:06.277Z"
   },
   {
    "duration": 124,
    "start_time": "2024-08-05T23:55:06.367Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-05T23:55:06.569Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-05T23:55:06.583Z"
   },
   {
    "duration": 1288,
    "start_time": "2024-08-05T23:55:06.593Z"
   },
   {
    "duration": 290,
    "start_time": "2024-08-05T23:55:07.883Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-05T23:55:08.176Z"
   },
   {
    "duration": 2393,
    "start_time": "2024-08-05T23:55:08.188Z"
   },
   {
    "duration": 204,
    "start_time": "2024-08-05T23:55:10.584Z"
   },
   {
    "duration": 474,
    "start_time": "2024-08-05T23:55:10.793Z"
   },
   {
    "duration": 392,
    "start_time": "2024-08-05T23:55:11.276Z"
   },
   {
    "duration": 123,
    "start_time": "2024-08-05T23:55:11.676Z"
   },
   {
    "duration": 88,
    "start_time": "2024-08-05T23:55:11.804Z"
   },
   {
    "duration": 1266,
    "start_time": "2024-08-05T23:55:11.895Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-05T23:55:13.167Z"
   },
   {
    "duration": 1269,
    "start_time": "2024-08-05T23:55:13.210Z"
   },
   {
    "duration": 443,
    "start_time": "2024-08-05T23:55:14.483Z"
   },
   {
    "duration": 775,
    "start_time": "2024-08-05T23:55:14.929Z"
   },
   {
    "duration": 2935,
    "start_time": "2024-08-05T23:55:15.710Z"
   },
   {
    "duration": 48,
    "start_time": "2024-08-05T23:55:18.648Z"
   },
   {
    "duration": 723,
    "start_time": "2024-08-05T23:55:18.699Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-06T08:41:36.132Z"
   },
   {
    "duration": 312,
    "start_time": "2024-08-06T14:33:44.135Z"
   },
   {
    "duration": 4976,
    "start_time": "2024-08-06T14:33:48.575Z"
   },
   {
    "duration": 119,
    "start_time": "2024-08-06T14:33:53.555Z"
   },
   {
    "duration": 18,
    "start_time": "2024-08-06T14:33:53.677Z"
   },
   {
    "duration": 51,
    "start_time": "2024-08-06T14:33:53.699Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-06T14:33:59.921Z"
   },
   {
    "duration": 1426,
    "start_time": "2024-08-06T14:34:16.346Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-06T14:34:25.241Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-06T14:34:26.060Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-06T14:34:26.884Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-06T14:34:28.030Z"
   },
   {
    "duration": 78,
    "start_time": "2024-08-06T14:34:58.787Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-06T14:35:02.295Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:35:02.636Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-06T14:35:03.225Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-06T14:35:04.009Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:35:05.234Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T14:36:00.473Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:36:01.843Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-06T14:36:03.944Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-06T14:36:05.254Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-06T14:36:06.684Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T14:38:47.568Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:38:48.378Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-06T14:38:49.179Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-06T14:38:50.780Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:38:52.567Z"
   },
   {
    "duration": 39,
    "start_time": "2024-08-06T14:39:14.628Z"
   },
   {
    "duration": 18,
    "start_time": "2024-08-06T14:39:14.950Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-06T14:39:15.404Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:39:18.065Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-06T14:40:15.575Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-06T14:40:28.856Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-06T14:44:32.418Z"
   },
   {
    "duration": 50,
    "start_time": "2024-08-06T14:44:53.310Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-06T14:45:01.238Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-06T14:45:01.974Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-06T14:45:02.966Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-06T14:45:05.017Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T14:45:10.014Z"
   },
   {
    "duration": 59,
    "start_time": "2024-08-06T14:45:16.531Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-06T14:45:20.250Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-06T14:45:27.967Z"
   },
   {
    "duration": 75,
    "start_time": "2024-08-06T14:45:46.763Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-06T14:46:16.291Z"
   },
   {
    "duration": 112,
    "start_time": "2024-08-06T14:46:32.822Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-06T14:46:57.694Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T14:48:57.919Z"
   },
   {
    "duration": 1011,
    "start_time": "2024-08-06T14:49:07.227Z"
   },
   {
    "duration": 3026,
    "start_time": "2024-08-06T14:50:49.630Z"
   },
   {
    "duration": 1745,
    "start_time": "2024-08-06T14:51:26.007Z"
   },
   {
    "duration": 1780,
    "start_time": "2024-08-06T14:52:47.269Z"
   },
   {
    "duration": 156,
    "start_time": "2024-08-06T14:53:16.182Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T14:54:07.977Z"
   },
   {
    "duration": 2040,
    "start_time": "2024-08-06T14:54:11.007Z"
   },
   {
    "duration": 2112,
    "start_time": "2024-08-06T14:54:59.830Z"
   },
   {
    "duration": 65,
    "start_time": "2024-08-06T14:56:07.280Z"
   },
   {
    "duration": 242,
    "start_time": "2024-08-06T14:56:18.893Z"
   },
   {
    "duration": 2845,
    "start_time": "2024-08-06T14:56:47.197Z"
   },
   {
    "duration": 2802,
    "start_time": "2024-08-06T14:57:58.153Z"
   },
   {
    "duration": 184,
    "start_time": "2024-08-06T14:58:45.368Z"
   },
   {
    "duration": 2754,
    "start_time": "2024-08-06T15:00:08.905Z"
   },
   {
    "duration": 85,
    "start_time": "2024-08-06T15:12:40.958Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T15:13:24.941Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T15:13:25.408Z"
   },
   {
    "duration": 26,
    "start_time": "2024-08-06T15:13:26.026Z"
   },
   {
    "duration": 42,
    "start_time": "2024-08-06T15:13:26.955Z"
   },
   {
    "duration": 48,
    "start_time": "2024-08-06T15:13:27.796Z"
   },
   {
    "duration": 53,
    "start_time": "2024-08-06T15:13:29.110Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-06T15:13:32.408Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-06T15:13:36.730Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-06T15:13:39.423Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-06T15:13:41.671Z"
   },
   {
    "duration": 99,
    "start_time": "2024-08-06T15:13:43.536Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-06T15:13:51.148Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T15:13:53.276Z"
   },
   {
    "duration": 1736,
    "start_time": "2024-08-06T15:13:54.413Z"
   },
   {
    "duration": 52,
    "start_time": "2024-08-06T15:14:01.207Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-06T15:14:06.156Z"
   },
   {
    "duration": 2062,
    "start_time": "2024-08-06T15:14:08.887Z"
   },
   {
    "duration": 48,
    "start_time": "2024-08-06T15:14:19.211Z"
   },
   {
    "duration": 2909,
    "start_time": "2024-08-06T15:14:48.825Z"
   },
   {
    "duration": 2836,
    "start_time": "2024-08-06T15:14:54.010Z"
   },
   {
    "duration": 69,
    "start_time": "2024-08-06T15:15:02.771Z"
   },
   {
    "duration": 95,
    "start_time": "2024-08-06T15:15:20.443Z"
   },
   {
    "duration": 120,
    "start_time": "2024-08-06T15:15:35.921Z"
   },
   {
    "duration": 45,
    "start_time": "2024-08-06T15:17:01.296Z"
   },
   {
    "duration": 45,
    "start_time": "2024-08-06T15:18:51.131Z"
   },
   {
    "duration": 75,
    "start_time": "2024-08-06T15:22:11.023Z"
   },
   {
    "duration": 77,
    "start_time": "2024-08-06T15:22:24.080Z"
   },
   {
    "duration": 1075,
    "start_time": "2024-08-06T15:23:26.477Z"
   },
   {
    "duration": 1198,
    "start_time": "2024-08-06T15:24:35.655Z"
   },
   {
    "duration": 1066,
    "start_time": "2024-08-06T15:24:43.930Z"
   },
   {
    "duration": 1049,
    "start_time": "2024-08-06T15:25:12.426Z"
   },
   {
    "duration": 37,
    "start_time": "2024-08-06T15:25:51.688Z"
   },
   {
    "duration": 1056,
    "start_time": "2024-08-06T15:26:38.284Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-06T15:28:00.742Z"
   },
   {
    "duration": 405,
    "start_time": "2024-08-06T15:29:06.926Z"
   },
   {
    "duration": 1030,
    "start_time": "2024-08-06T15:29:46.952Z"
   },
   {
    "duration": 411,
    "start_time": "2024-08-06T15:29:58.659Z"
   },
   {
    "duration": 284,
    "start_time": "2024-08-06T15:30:03.814Z"
   },
   {
    "duration": 326,
    "start_time": "2024-08-06T15:30:08.786Z"
   },
   {
    "duration": 339,
    "start_time": "2024-08-06T15:30:12.185Z"
   },
   {
    "duration": 367,
    "start_time": "2024-08-06T15:30:15.029Z"
   },
   {
    "duration": 386,
    "start_time": "2024-08-06T15:30:17.403Z"
   },
   {
    "duration": 686,
    "start_time": "2024-08-06T15:30:20.543Z"
   },
   {
    "duration": 379,
    "start_time": "2024-08-06T15:30:28.665Z"
   },
   {
    "duration": 381,
    "start_time": "2024-08-06T15:30:44.272Z"
   },
   {
    "duration": 284,
    "start_time": "2024-08-06T15:30:48.452Z"
   },
   {
    "duration": 401,
    "start_time": "2024-08-06T15:30:53.252Z"
   },
   {
    "duration": 376,
    "start_time": "2024-08-06T15:30:59.420Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-06T15:32:28.570Z"
   },
   {
    "duration": 35,
    "start_time": "2024-08-06T15:32:39.872Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-06T15:33:03.105Z"
   },
   {
    "duration": 386,
    "start_time": "2024-08-06T15:33:06.941Z"
   },
   {
    "duration": 381,
    "start_time": "2024-08-06T15:33:25.207Z"
   },
   {
    "duration": 379,
    "start_time": "2024-08-06T15:34:29.982Z"
   },
   {
    "duration": 355,
    "start_time": "2024-08-06T15:42:48.709Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-06T15:46:18.621Z"
   },
   {
    "duration": 40,
    "start_time": "2024-08-06T15:46:27.235Z"
   },
   {
    "duration": 44,
    "start_time": "2024-08-06T15:48:05.578Z"
   },
   {
    "duration": 615,
    "start_time": "2024-08-06T15:50:11.388Z"
   },
   {
    "duration": 2400,
    "start_time": "2024-08-06T15:52:46.473Z"
   },
   {
    "duration": 2483,
    "start_time": "2024-08-06T15:53:51.516Z"
   },
   {
    "duration": 2393,
    "start_time": "2024-08-06T15:58:02.517Z"
   },
   {
    "duration": 2502,
    "start_time": "2024-08-06T15:58:29.982Z"
   },
   {
    "duration": 116,
    "start_time": "2024-08-06T15:58:46.836Z"
   },
   {
    "duration": 31,
    "start_time": "2024-08-06T15:59:02.126Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-06T15:59:29.584Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-06T16:03:26.679Z"
   },
   {
    "duration": 2374,
    "start_time": "2024-08-06T16:03:47.036Z"
   },
   {
    "duration": 2493,
    "start_time": "2024-08-06T16:03:53.224Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-06T16:03:59.239Z"
   },
   {
    "duration": 629,
    "start_time": "2024-08-06T16:04:08.475Z"
   },
   {
    "duration": 102,
    "start_time": "2024-08-06T16:09:01.643Z"
   },
   {
    "duration": 43,
    "start_time": "2024-08-06T16:10:27.982Z"
   },
   {
    "duration": 34,
    "start_time": "2024-08-06T16:12:10.579Z"
   },
   {
    "duration": 33,
    "start_time": "2024-08-06T16:12:39.759Z"
   },
   {
    "duration": 1406,
    "start_time": "2024-08-06T16:43:00.319Z"
   },
   {
    "duration": 49,
    "start_time": "2024-08-06T16:43:01.728Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-06T16:43:01.781Z"
   },
   {
    "duration": 59,
    "start_time": "2024-08-06T16:43:01.805Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-06T16:43:01.868Z"
   },
   {
    "duration": 76,
    "start_time": "2024-08-06T16:43:01.910Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-06T16:43:01.988Z"
   },
   {
    "duration": 46,
    "start_time": "2024-08-06T16:43:02.000Z"
   },
   {
    "duration": 187,
    "start_time": "2024-08-06T16:43:02.049Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-06T16:43:02.244Z"
   },
   {
    "duration": 194,
    "start_time": "2024-08-06T16:43:02.340Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-06T16:43:02.537Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-06T16:43:02.550Z"
   },
   {
    "duration": 1901,
    "start_time": "2024-08-06T16:43:02.635Z"
   },
   {
    "duration": 203,
    "start_time": "2024-08-06T16:43:04.539Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-06T16:43:04.745Z"
   },
   {
    "duration": 2389,
    "start_time": "2024-08-06T16:43:04.756Z"
   },
   {
    "duration": 195,
    "start_time": "2024-08-06T16:43:07.148Z"
   },
   {
    "duration": 3091,
    "start_time": "2024-08-06T16:43:07.346Z"
   },
   {
    "duration": 2989,
    "start_time": "2024-08-06T16:43:10.445Z"
   },
   {
    "duration": 201,
    "start_time": "2024-08-06T16:43:13.437Z"
   },
   {
    "duration": 252,
    "start_time": "2024-08-06T16:43:13.647Z"
   },
   {
    "duration": 80,
    "start_time": "2024-08-06T16:43:13.902Z"
   },
   {
    "duration": 1102,
    "start_time": "2024-08-06T16:43:13.985Z"
   },
   {
    "duration": 1106,
    "start_time": "2024-08-06T16:43:15.089Z"
   },
   {
    "duration": 44,
    "start_time": "2024-08-06T16:43:16.200Z"
   },
   {
    "duration": 417,
    "start_time": "2024-08-06T16:43:16.248Z"
   },
   {
    "duration": 400,
    "start_time": "2024-08-06T16:43:16.667Z"
   },
   {
    "duration": 45,
    "start_time": "2024-08-06T16:43:17.070Z"
   },
   {
    "duration": 649,
    "start_time": "2024-08-06T16:43:17.135Z"
   },
   {
    "duration": 2505,
    "start_time": "2024-08-06T16:43:17.787Z"
   },
   {
    "duration": 2586,
    "start_time": "2024-08-06T16:43:20.295Z"
   },
   {
    "duration": 50,
    "start_time": "2024-08-06T16:43:22.884Z"
   },
   {
    "duration": 698,
    "start_time": "2024-08-06T16:43:22.936Z"
   },
   {
    "duration": 36,
    "start_time": "2024-08-06T16:43:23.638Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
