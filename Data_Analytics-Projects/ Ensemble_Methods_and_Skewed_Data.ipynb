{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ensemble Methods and Skewed Data\n",
    "For this project, we will explore two ensemble methods:\n",
    "  - AdaBoost\n",
    "  - Random Forests\n",
    "\n",
    "We will also apply different KPIs (key performance indicators) that are more appropriate to highly skewed data sets. \n",
    "\n",
    "At the end of this project, you should know:\n",
    "- How to train and use ensemble classifiers\n",
    "- How to characterize model performance with ROC curves\n",
    "- The difference between accuracy, true positive rate, and positive predictive value.\n",
    "\n",
    "## Credit Card dataset\n",
    "Our dataset (in `cc.csv.gz`) contains transactions made by credit cards in September 2013 by european cardholders. It contains transactions that over two days, where we have 237 frauds out of 142,167 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.17% of all transactions.\n",
    "\n",
    "The dataset contains only numerical input variables which are the result of a [PCA transformation](https://en.wikipedia.org/wiki/Principal_component_analysis). Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. \n",
    "- Features **V1**, **V2**, ..., **V28** are the principal components obtained with PCA.\n",
    "- The only features which have not been transformed with PCA are **Time**, **Amount**, and **Class**.\n",
    "  - **Time** contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
    "  - **Amount** is the transaction amount in Euros. \n",
    "  - **Class** is the response variable. If the transation was fraudulent, it equals 1. Otherwise, it equals 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not import any libraries (i.e. sklearn, scipy, etc.), except for\n",
    "# Python builtin libraries, unless otherwise specified.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 \n",
    "\n",
    "**Parition the data for cross validation**\n",
    "- Load the data.\n",
    "- Split the data set into $X$ (the feature dataframe, `df_X`), and $y$ (the target series `s_y`). \n",
    "- Partition the data into $k = 3$ folds using **stratified $k$-folds** (see below).\n",
    "\n",
    "We know this is a _super_ skewed data set, so we worry about our target class being underrepresented in a random k-fold selection. With this in mind, we use a ***stratifed* $k$-fold** since it will preserve our class balance in our experiements.\n",
    "- Use $k=3$. \n",
    "- Instantiate an instance of the [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) class.\n",
    "   - Use a `random_state` of 23.\n",
    "- Use the generator `split` to populate the test and train dictonaries:\n",
    "   - `d_train_df_X`: \n",
    "      - Key: Fold number ($1$ to $k$ inclusive)\n",
    "      - Value: The attribute training DataFrame for that fold\n",
    "   - `d_test_df_X`: key is the fold number, value is \n",
    "      - Key: Fold number\n",
    "      - Value: The attribute testing DataFrame for that fold\n",
    "   - `d_train_s_y`: key is the fold number, value is \n",
    "      - Key: Fold number\n",
    "      - Value: The target training Series for that fold\n",
    "   - `d_train_s_y`: key is the fold number, value is \n",
    "      - Key: Fold number\n",
    "      - Value: The target testing Series for that fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the credit card data provided, we'll use sklearn methods to do cross validation\n",
    "# to estimate error.\n",
    "#\n",
    "# The dataset is compressed, since it's really big (77 MB uncompressed)\n",
    "df_cc = pd.read_csv('cc.csv.gz')\n",
    "\n",
    "# Split the full dataframe into the training DataFrame and target Series.\n",
    "df_X = df_cc.loc[:, df_cc.columns != 'Class']\n",
    "s_y = df_cc['Class']\n",
    "# Initialize a Stratified k-fold predictor, skf\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72222.0</td>\n",
       "      <td>1.190580</td>\n",
       "      <td>-0.188208</td>\n",
       "      <td>0.323583</td>\n",
       "      <td>-0.017402</td>\n",
       "      <td>-0.758874</td>\n",
       "      <td>-1.132340</td>\n",
       "      <td>-0.021169</td>\n",
       "      <td>-0.201165</td>\n",
       "      <td>0.364626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.103901</td>\n",
       "      <td>-0.442050</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.438578</td>\n",
       "      <td>0.164461</td>\n",
       "      <td>0.930956</td>\n",
       "      <td>-0.096429</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65707.0</td>\n",
       "      <td>1.282559</td>\n",
       "      <td>0.270023</td>\n",
       "      <td>0.134166</td>\n",
       "      <td>0.618716</td>\n",
       "      <td>-0.291346</td>\n",
       "      <td>-0.893310</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>-0.119655</td>\n",
       "      <td>0.219620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139638</td>\n",
       "      <td>-0.324119</td>\n",
       "      <td>-0.983490</td>\n",
       "      <td>0.098567</td>\n",
       "      <td>-0.044337</td>\n",
       "      <td>0.228126</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>-0.030385</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47048.0</td>\n",
       "      <td>-0.777343</td>\n",
       "      <td>0.081844</td>\n",
       "      <td>1.910231</td>\n",
       "      <td>1.194221</td>\n",
       "      <td>1.018604</td>\n",
       "      <td>0.438980</td>\n",
       "      <td>0.183102</td>\n",
       "      <td>0.017511</td>\n",
       "      <td>-0.193956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408923</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>0.361164</td>\n",
       "      <td>-0.159239</td>\n",
       "      <td>-0.743651</td>\n",
       "      <td>0.092543</td>\n",
       "      <td>-0.165719</td>\n",
       "      <td>-0.022370</td>\n",
       "      <td>-0.093903</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127379.0</td>\n",
       "      <td>-0.887548</td>\n",
       "      <td>1.417217</td>\n",
       "      <td>0.753405</td>\n",
       "      <td>2.257167</td>\n",
       "      <td>1.392043</td>\n",
       "      <td>0.680374</td>\n",
       "      <td>0.531104</td>\n",
       "      <td>0.609270</td>\n",
       "      <td>-1.725432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220606</td>\n",
       "      <td>-0.345603</td>\n",
       "      <td>-1.323231</td>\n",
       "      <td>0.219222</td>\n",
       "      <td>-0.080944</td>\n",
       "      <td>-0.791587</td>\n",
       "      <td>-0.773272</td>\n",
       "      <td>0.040113</td>\n",
       "      <td>0.099547</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151137.0</td>\n",
       "      <td>1.819262</td>\n",
       "      <td>-0.445540</td>\n",
       "      <td>-0.186929</td>\n",
       "      <td>1.268411</td>\n",
       "      <td>-0.483948</td>\n",
       "      <td>0.164878</td>\n",
       "      <td>-0.572012</td>\n",
       "      <td>0.022557</td>\n",
       "      <td>1.071776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.065024</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.099592</td>\n",
       "      <td>-0.728832</td>\n",
       "      <td>-0.236169</td>\n",
       "      <td>-0.722497</td>\n",
       "      <td>0.068185</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142399</th>\n",
       "      <td>65324.0</td>\n",
       "      <td>-0.559946</td>\n",
       "      <td>0.103121</td>\n",
       "      <td>0.319922</td>\n",
       "      <td>-0.973168</td>\n",
       "      <td>1.226528</td>\n",
       "      <td>-1.277010</td>\n",
       "      <td>1.106265</td>\n",
       "      <td>-0.394966</td>\n",
       "      <td>-0.566084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401564</td>\n",
       "      <td>0.160310</td>\n",
       "      <td>0.518538</td>\n",
       "      <td>0.152764</td>\n",
       "      <td>0.102517</td>\n",
       "      <td>-0.821350</td>\n",
       "      <td>0.710368</td>\n",
       "      <td>0.148434</td>\n",
       "      <td>0.049325</td>\n",
       "      <td>57.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142400</th>\n",
       "      <td>135695.0</td>\n",
       "      <td>1.833353</td>\n",
       "      <td>-0.450252</td>\n",
       "      <td>-0.469224</td>\n",
       "      <td>0.831620</td>\n",
       "      <td>0.415326</td>\n",
       "      <td>2.161855</td>\n",
       "      <td>-1.088867</td>\n",
       "      <td>0.775843</td>\n",
       "      <td>0.984546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349295</td>\n",
       "      <td>0.037067</td>\n",
       "      <td>0.266594</td>\n",
       "      <td>0.349396</td>\n",
       "      <td>-1.025944</td>\n",
       "      <td>-0.514426</td>\n",
       "      <td>-0.739087</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>-0.045159</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142401</th>\n",
       "      <td>62620.0</td>\n",
       "      <td>-3.324328</td>\n",
       "      <td>-2.771390</td>\n",
       "      <td>1.883730</td>\n",
       "      <td>0.154892</td>\n",
       "      <td>0.142827</td>\n",
       "      <td>-1.327852</td>\n",
       "      <td>-1.089896</td>\n",
       "      <td>0.762312</td>\n",
       "      <td>-1.578990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561959</td>\n",
       "      <td>0.165352</td>\n",
       "      <td>-0.626969</td>\n",
       "      <td>0.314974</td>\n",
       "      <td>0.442229</td>\n",
       "      <td>0.227412</td>\n",
       "      <td>-0.591151</td>\n",
       "      <td>-0.054984</td>\n",
       "      <td>-0.393804</td>\n",
       "      <td>205.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142402</th>\n",
       "      <td>39607.0</td>\n",
       "      <td>-2.457284</td>\n",
       "      <td>-6.208370</td>\n",
       "      <td>-1.997703</td>\n",
       "      <td>1.251932</td>\n",
       "      <td>-2.132900</td>\n",
       "      <td>0.456995</td>\n",
       "      <td>2.335032</td>\n",
       "      <td>-0.384962</td>\n",
       "      <td>-0.115378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.750285</td>\n",
       "      <td>0.974168</td>\n",
       "      <td>-1.585880</td>\n",
       "      <td>-1.585928</td>\n",
       "      <td>-0.181570</td>\n",
       "      <td>-0.622555</td>\n",
       "      <td>0.678623</td>\n",
       "      <td>-0.442699</td>\n",
       "      <td>0.318217</td>\n",
       "      <td>1915.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142403</th>\n",
       "      <td>147608.0</td>\n",
       "      <td>1.871051</td>\n",
       "      <td>0.221899</td>\n",
       "      <td>-0.042586</td>\n",
       "      <td>3.531304</td>\n",
       "      <td>0.248165</td>\n",
       "      <td>1.285607</td>\n",
       "      <td>-0.675794</td>\n",
       "      <td>0.367247</td>\n",
       "      <td>-0.541569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204570</td>\n",
       "      <td>0.186848</td>\n",
       "      <td>0.601374</td>\n",
       "      <td>0.142002</td>\n",
       "      <td>0.178048</td>\n",
       "      <td>-0.165776</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>-0.038850</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142404 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        72222.0  1.190580 -0.188208  0.323583 -0.017402 -0.758874 -1.132340   \n",
       "1        65707.0  1.282559  0.270023  0.134166  0.618716 -0.291346 -0.893310   \n",
       "2        47048.0 -0.777343  0.081844  1.910231  1.194221  1.018604  0.438980   \n",
       "3       127379.0 -0.887548  1.417217  0.753405  2.257167  1.392043  0.680374   \n",
       "4       151137.0  1.819262 -0.445540 -0.186929  1.268411 -0.483948  0.164878   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "142399   65324.0 -0.559946  0.103121  0.319922 -0.973168  1.226528 -1.277010   \n",
       "142400  135695.0  1.833353 -0.450252 -0.469224  0.831620  0.415326  2.161855   \n",
       "142401   62620.0 -3.324328 -2.771390  1.883730  0.154892  0.142827 -1.327852   \n",
       "142402   39607.0 -2.457284 -6.208370 -1.997703  1.251932 -2.132900  0.456995   \n",
       "142403  147608.0  1.871051  0.221899 -0.042586  3.531304  0.248165  1.285607   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "0      -0.021169 -0.201165  0.364626  ... -0.000226 -0.103901 -0.442050   \n",
       "1       0.005146 -0.119655  0.219620  ... -0.139638 -0.324119 -0.983490   \n",
       "2       0.183102  0.017511 -0.193956  ...  0.408923  0.072843  0.361164   \n",
       "3       0.531104  0.609270 -1.725432  ... -0.220606 -0.345603 -1.323231   \n",
       "4      -0.572012  0.022557  1.071776  ...  0.010713  0.065024  0.222817   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "142399  1.106265 -0.394966 -0.566084  ...  0.401564  0.160310  0.518538   \n",
       "142400 -1.088867  0.775843  0.984546  ... -0.349295  0.037067  0.266594   \n",
       "142401 -1.089896  0.762312 -1.578990  ...  0.561959  0.165352 -0.626969   \n",
       "142402  2.335032 -0.384962 -0.115378  ...  3.750285  0.974168 -1.585880   \n",
       "142403 -0.675794  0.367247 -0.541569  ... -0.204570  0.186848  0.601374   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28   Amount  \n",
       "0       0.024706  0.438578  0.164461  0.930956 -0.096429  0.012989    57.00  \n",
       "1       0.098567 -0.044337  0.228126  0.120401 -0.030385  0.024717     0.89  \n",
       "2      -0.159239 -0.743651  0.092543 -0.165719 -0.022370 -0.093903    40.00  \n",
       "3       0.219222 -0.080944 -0.791587 -0.773272  0.040113  0.099547     9.08  \n",
       "4       0.099592 -0.728832 -0.236169 -0.722497  0.068185 -0.010816    90.00  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "142399  0.152764  0.102517 -0.821350  0.710368  0.148434  0.049325    57.81  \n",
       "142400  0.349396 -1.025944 -0.514426 -0.739087  0.106196 -0.045159     1.00  \n",
       "142401  0.314974  0.442229  0.227412 -0.591151 -0.054984 -0.393804   205.77  \n",
       "142402 -1.585928 -0.181570 -0.622555  0.678623 -0.442699  0.318217  1915.01  \n",
       "142403  0.142002  0.178048 -0.165776  0.006957  0.009314 -0.038850     4.95  \n",
       "\n",
       "[142404 rows x 30 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_train_df_X = {}\n",
    "d_test_df_X = {}\n",
    "d_train_s_y = {}\n",
    "d_test_s_y = {}\n",
    "\n",
    "\n",
    "# Construct the above dictionaries.\n",
    "for i, (train_index, test_index) in enumerate(skf.split(df_X,s_y)):\n",
    "    #print(f\"Fold {i}:\")\n",
    "    #print(f\"  Train: index={train_index}\")\n",
    "    #print(f\"  Test:  index={test_index}\")\n",
    "    \n",
    "    d_train_df_X[i+1] = pd.DataFrame(df_X.values[train_index])\n",
    "    d_test_df_X[i+1] = pd.DataFrame(df_X.values[test_index])\n",
    "    d_train_s_y[i+1] = pd.Series(s_y.values[train_index])\n",
    "    d_test_s_y[i+1] = pd.Series(s_y.values[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "0    47389\n",
      "1       79\n",
      "dtype: int64\n",
      "\n",
      "Fold 2:\n",
      "0    47389\n",
      "1       79\n",
      "dtype: int64\n",
      "\n",
      "Fold 3:\n",
      "0    47389\n",
      "1       79\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the test data and verify that the target training datasets are as\n",
    "# equally distributed as possible.\n",
    "for key in d_test_s_y.keys():\n",
    "    print(f'Fold {key}:')\n",
    "    print(d_test_s_y[key].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q2\n",
    "**Write functions to compute performance metrics**\n",
    "\n",
    "For this problem, we will write four functions to test the performance of a classifier.\n",
    "- Each function will take in:\n",
    "    - `y_pred`, a Pandas Series of prediciton target classes\n",
    "    - `y_label` a Pandas Series of true target labels.\n",
    "- Each function should return a `float`ing point number between 0.0 and 1.0\n",
    "\n",
    "You'll write the following four functions:\n",
    "- `tpr(y_pred, y_label)`: Computes the **true positive rate**\n",
    "- `fpr(y_pred, y_label)`: Computes the **false positive rate**\n",
    "- `ppv(y_pred, y_label)`: Computes the **positive predictive value**.\n",
    "- `accuracy(y_pred, y_label)`: Computes the **accuracy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write some helper functions to compute TPR, FPR, PPV, and accuracy.\n",
    "def tpr(y_pred: pd.Series, y_label : pd.Series) -> float:\n",
    "    \"\"\"Compute the true postive rate.\n",
    "\n",
    "    Note: It should be between 0 and 1 (i.e. *not* a percentage)\n",
    "    \"\"\"\n",
    "    #print('y_pred', y_pred)\n",
    "    #print('t_label', y_label)\n",
    "    tp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 1:\n",
    "            tp +=1\n",
    "    tn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 0:\n",
    "            tn +=1\n",
    "    fp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 1:\n",
    "            fp +=1\n",
    "    \n",
    "    fn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 0:\n",
    "            fn +=1\n",
    "    #print('tp', tp)\n",
    "    #print('tn', tn)\n",
    "    #print('fp', fp)\n",
    "    #print('fn', fn)\n",
    "    tpr_ = tp / (tp+fn)\n",
    "    \n",
    "    return tpr_\n",
    "\n",
    "\n",
    "def fpr(y_pred: pd.Series, y_label : pd.Series) -> float:\n",
    "    \"\"\"Compute the false postive rate.\n",
    "\n",
    "    Note: It should be between 0 and 1 (i.e. *not* a percentage)\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 1:\n",
    "            tp +=1\n",
    "    tn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 0:\n",
    "            tn +=1\n",
    "    fp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 1:\n",
    "            fp +=1\n",
    "    \n",
    "    fn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 0:\n",
    "            fn +=1\n",
    "    \n",
    "    fpr_ = fp/ (fp+tn)\n",
    "    return fpr_\n",
    "\n",
    "\n",
    "def ppv(y_pred: pd.Series, y_label : pd.Series) -> float:\n",
    "    \"\"\"Compute the positive predictive value.\n",
    "\n",
    "    Note: It should be between 0 and 1 (i.e. *not* a percentage)\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 1:\n",
    "            tp +=1\n",
    "    tn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 0:\n",
    "            tn +=1\n",
    "    fp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 1:\n",
    "            fp +=1\n",
    "    \n",
    "    fn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 0:\n",
    "            fn +=1\n",
    "    \n",
    "    ppv_ = tp/(tp+fp)\n",
    "    \n",
    "    return ppv_\n",
    "\n",
    "\n",
    "def accuracy(y_pred: pd.Series, y_label : pd.Series) -> float:\n",
    "    \"\"\"Compute the accuracy.\n",
    "\n",
    "    Note: It should be between 0 and 1 (i.e. *not* a percentage)\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 1:\n",
    "            tp +=1\n",
    "    tn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 0:\n",
    "            tn +=1\n",
    "    fp = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 0 and p == 1:\n",
    "            fp +=1\n",
    "    \n",
    "    fn = 0\n",
    "    for t, p in zip(y_label, y_pred):\n",
    "        if t == 1 and p == 0:\n",
    "            fn +=1\n",
    "    \n",
    "    accuracy_ = (tp+tn)/(tp+fp+fn+tn)\n",
    "    return accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can write some tests for your functions here, if you wish.\n",
    "tpr_test = tpr(d_test_s_y[1], d_test_s_y[2])\n",
    "tpr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q3 \n",
    "\n",
    "**Test the Performance of AdaBoost**\n",
    "\n",
    "\n",
    "When we talked about AdaBoost in class, we used a collection of \"Decision Stumps\". In this project, we will use the implementation of [`AdaBoostClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) in scikit-learn.  \n",
    "- As you browse the documentation, you will notice that the default base esimator for `AdaBoostClassifier` is a `DecisionTreeClassifier(max_depth=1)` (i.e. exactly what we learned, the decision stump).\n",
    "- After you fit an `AdaBoost` model, you can call these methods:\n",
    "     - `predict`, which yields a class prediction\n",
    "     - `predict_proba`, which yieldst the probability of being in the class `0` or the class `1`. (These probabilities are used when creating ROC curves.)\n",
    "\n",
    "For this problem, we will do the following:\n",
    "- Loop over the $k$ folds using the dictionaries from Q1.\n",
    "- For each fold:\n",
    "    1. Fit an `AdaBoostClassifier` on the fold's training set.\n",
    "        - Make sure that `n_estimators=25`, and `random_state=23`.\n",
    "    2. Get the `AdaBoostClassifier`'s predictions on the fold's testing set.\n",
    "    3. Compute the ROC curve, and ROC area under curve (AUC) of the classifier on the fold's testing set.\n",
    "    3. Compute the accuracy, TPR, PPV, and FPR of the classifier on the fold's testing set.\n",
    "- **For the third fold only**, save the class predictions into a variable called `y_hat_ab` for use in Q5.\n",
    "- Plot the ROC curves for each fold on one graph.\n",
    "\n",
    "*Hints*:\n",
    "- For plotting the ROC curve, the following functions should be useful:\n",
    "    - [`roc_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) computes an array of points which you can use to plot your curve. It returns `fpr` and `tpr`, which represent points on the curve, and `thresholds`, which you will not need.\n",
    "    - [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) computes the AUC of an ROC curve.\n",
    "    - You should avoid using `plot_roc_curve`, as it is deprecated. \n",
    "    - Likewise, you should avoid [`ROCCurveDisplay`](https://scikit-learn.org/0.24/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay), since it only lets us visualize one fold at a time. However, its related [tutorial](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html) may be helpful.\n",
    "\n",
    "*Note*: This can take a few minutes to run.\n",
    "- To make debugging faster, you can set `n_estimators=1` or some small number. However, when obtaining the final results, please make sure that `n_estimators=25`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 TPR: 0.620 FPR: 0.000 PPV: 0.817 Accuracy: 0.999 AUC: 0.966\n",
      "Fold 2 TPR: 0.620 FPR: 0.000 PPV: 0.754 Accuracy: 0.999 AUC: 0.963\n",
      "Fold 3 TPR: 0.709 FPR: 0.000 PPV: 0.800 Accuracy: 0.999 AUC: 0.958\n"
     ]
    }
   ],
   "source": [
    "fpr_curves_ab = {} # Contains the fpr curve points generated by roc_curve on each fold.\n",
    "tpr_curves_ab = {} # Contains the tpr curve points generated by roc_curve on each fold.\n",
    "\n",
    "aucs_ab = {} # Contains the AUC value generated by roc_auc_score on each fold.\n",
    "tprs_ab = {} # Contains the TPR you compute on each fold.\n",
    "fprs_ab = {} # Contains the FPR you compute on each fold.\n",
    "ppvs_ab = {} # Contains the PPV you compute on each fold.\n",
    "accs_ab = {} # Contains the accuracy you compute on each fold.\n",
    "\n",
    "for k in d_train_df_X.keys():\n",
    "    print(f'Fold {k}', end='')\n",
    "    \n",
    "    # Create an AdaBoost classifier and fit it to the dataset.\n",
    "    clf_ab = AdaBoostClassifier(n_estimators=25, random_state=23)\n",
    "    clf_ab.fit(d_train_df_X[k], d_train_s_y[k])\n",
    "\n",
    "    # Compute the predicitons (both class and probability) on the test set.\n",
    "    y_pred = clf_ab.predict(d_test_df_X[k])\n",
    "    y_pred_prob = clf_ab.predict_proba(d_test_df_X[k])\n",
    "\n",
    "    # Compute the ROC curve and AUC score. Hint: use roc_curve / roc_auc_score.\n",
    "    #print(y_pred_prob.T[0])\n",
    "    fpr_curves, tpr_curves, thresholds = roc_curve(d_test_s_y[k],y_pred_prob[:, 1])\n",
    "    fpr_curves_ab[k] = fpr_curves\n",
    "    tpr_curves_ab[k] = tpr_curves\n",
    "    aucs_ab[k] = roc_auc_score(d_test_s_y[k], y_pred_prob[:, 1])\n",
    "\n",
    "    # Compute the raw TPR, PPV, FPR, and accuracy. Do not use any library functions.\n",
    "    tprs_ab[k] = tpr(y_pred, d_test_s_y[k])\n",
    "    fprs_ab[k] = fpr(y_pred, d_test_s_y[k])\n",
    "    ppvs_ab[k] = ppv(y_pred, d_test_s_y[k])\n",
    "    accs_ab[k] = accuracy(y_pred, d_test_s_y[k])\n",
    "\n",
    "    print(f' TPR: {tprs_ab[k]:.3f} FPR: {fprs_ab[k]:.3f} PPV: {ppvs_ab[k]:.3f} Accuracy: {accs_ab[k]:.3f} AUC: {aucs_ab[k]:.3f}')\n",
    "\n",
    "    # Save the third fold's predicitons\n",
    "    if k == 3:\n",
    "        y_hat_ab = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "for k in d_train_df_X.keys():\n",
    "    plt.plot(fpr_curves_ab[k],tpr_curves_ab[k])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR min: 0.620 mean: 0.650 max: 0.709\n",
      "FPR min: 0.000 mean: 0.000 max: 0.000\n",
      "PPV min: 0.754 mean: 0.790 max: 0.817\n",
      "ACC min: 0.999 mean: 0.999 max: 0.999\n",
      "AUC min: 0.958 mean: 0.962 max: 0.966\n"
     ]
    }
   ],
   "source": [
    "# Print min, mean, max metrics.\n",
    "print(f'TPR min: {min(tprs_ab.values()):.3f} mean: {np.average(list(tprs_ab.values())):.3f} max: {max(tprs_ab.values()):.3f}')\n",
    "print(f'FPR min: {min(fprs_ab.values()):.3f} mean: {np.average(list(fprs_ab.values())):.3f} max: {max(fprs_ab.values()):.3f}')\n",
    "print(f'PPV min: {min(ppvs_ab.values()):.3f} mean: {np.average(list(ppvs_ab.values())):.3f} max: {max(ppvs_ab.values()):.3f}')\n",
    "print(f'ACC min: {min(accs_ab.values()):.3f} mean: {np.average(list(accs_ab.values())):.3f} max: {max(accs_ab.values()):.3f}')\n",
    "print(f'AUC min: {min(aucs_ab.values()):.3f} mean: {np.average(list(aucs_ab.values())):.3f} max: {max(aucs_ab.values()):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q4 \n",
    "\n",
    "**Test the Performance of Random Forests**\n",
    "\n",
    "Now, let's try another ensemble method: Random Forests, again using the scikit-learn implementation, which for this case is [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "- Following our book, we will build complete trees, with no pruning. That means that:\n",
    "    - Every leaf in the tree will be completelely pure.\n",
    "    - If you exam an individual decision tree, it would be overtrained to our training set.  \n",
    "- To avoid this, while building the decision trees, at every internal node, we select $p$ attributes at random, and then find the best split that minimizes impurtity.  \n",
    "    - The value $p$ is a hyperparameter of the Random Forest, corresponding to the `max_features` parameter for the `RandomForestClassifier`.\n",
    "\n",
    "As in Q3, we will do the following for this problem:\n",
    "- Loop over the $k$ folds using the dictionaries from Q1.\n",
    "- For each fold:\n",
    "    1. Fit an `RandomForestClassifier` on the fold's training set.\n",
    "        - Make sure that `criterion=\"entropy\"`, `max_features=\"sqrt\"`, and `random_state=23`.\n",
    "    2. Get the `RandomForestClassifier`'s predictions on the fold's testing set.\n",
    "    3. Compute the ROC curve, and ROC area under curve (AUC) of the classifier on the fold's testing set.\n",
    "    3. Compute the accuracy, TPR, PPV, and FPR of the classifier on the fold's testing set.\n",
    "- **For the third fold only**, save the class predictions into a variable called `y_hat_rf` for use in Q5.\n",
    "- Plot the ROC curves for each fold on one graph.\n",
    "\n",
    "\n",
    "*Note*: This can take a few minutes to run.\n",
    "- To make debugging faster, you can set (((`n_estimators=1` or some small number. However, when obtaining the final results, please make sure that `n_estimators=25`.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 TPR: 0.747 FPR: 0.000 PPV: 0.922 Accuracy: 0.999 AUC: 0.911\n",
      "Fold 2 TPR: 0.797 FPR: 0.000 PPV: 0.913 Accuracy: 1.000 AUC: 0.949\n",
      "Fold 3 TPR: 0.772 FPR: 0.000 PPV: 0.968 Accuracy: 1.000 AUC: 0.930\n"
     ]
    }
   ],
   "source": [
    "fpr_curves_rf = {} # Contains the fpr curve points generated by roc_curve on each fold.\n",
    "tpr_curves_rf = {} # Contains the tpr curve points generated by roc_curve on each fold.\n",
    "\n",
    "aucs_rf = {} # Contains the AUC value generated by roc_auc_score on each fold.\n",
    "tprs_rf = {} # Contains the TPR you compute on each fold.\n",
    "fprs_rf = {} # Contains the FPR you compute on each fold.\n",
    "ppvs_rf = {} # Contains the PPV you compute on each fold.\n",
    "accs_rf = {} # Contains the accuracy you compute on each fold.\n",
    "\n",
    "for k in d_train_df_X.keys():\n",
    "    print(f'Fold {k}', end='')\n",
    "    \n",
    "    # Create an AdaBoost classifier and fit it to the dataset.\n",
    "    clf_rf = RandomForestClassifier(n_estimators=25,criterion=\"entropy\", max_features=\"sqrt\",random_state=23)\n",
    "    clf_rf.fit(d_train_df_X[k], d_train_s_y[k])\n",
    "    # Compute the predicitons (both class and probability) on the test set.\n",
    "    y_pred = clf_rf.predict(d_test_df_X[k])\n",
    "    y_pred_prob = clf_rf.predict_proba(d_test_df_X[k])\n",
    "\n",
    "    # Compute the ROC curve and AUC score. Hint: use roc_curve / roc_auc_score.\n",
    "    fpr_curves, tpr_curves, thresholds = roc_curve(d_test_s_y[k],y_pred_prob[:, 1])\n",
    "    fpr_curves_rf[k] = fpr_curves\n",
    "    tpr_curves_rf[k] = tpr_curves\n",
    "    aucs_rf[k] = roc_auc_score(d_test_s_y[k], y_pred_prob[:, 1])\n",
    "\n",
    "    # Compute the raw TPR, PPV, FPR, and accuracy. Do not use any library functions.\n",
    "    tprs_rf[k] = tpr(y_pred, d_test_s_y[k])\n",
    "    fprs_rf[k] = fpr(y_pred, d_test_s_y[k])\n",
    "    ppvs_rf[k] = ppv(y_pred, d_test_s_y[k])\n",
    "    accs_rf[k] = accuracy(y_pred, d_test_s_y[k])\n",
    "\n",
    "    print(f' TPR: {tprs_rf[k]:.3f} FPR: {fprs_rf[k]:.3f} PPV: {ppvs_rf[k]:.3f} Accuracy: {accs_rf[k]:.3f} AUC: {aucs_rf[k]:.3f}')\n",
    "\n",
    "    # Save the third fold's predicitons\n",
    "    if k == 3:\n",
    "        y_hat_rf = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "for k in d_train_df_X.keys():\n",
    "    plt.plot(fpr_curves_rf[k],tpr_curves_rf[k])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR min: 0.747 mean: 0.772 max: 0.797\n",
      "FPR min: 0.000 mean: 0.000 max: 0.000\n",
      "PPV min: 0.913 mean: 0.934 max: 0.968\n",
      "ACC min: 0.999 mean: 1.000 max: 1.000\n",
      "AUC min: 0.911 mean: 0.930 max: 0.949\n"
     ]
    }
   ],
   "source": [
    "# Print min, mean, max metrics.\n",
    "print(f'TPR min: {min(tprs_rf.values()):.3f} mean: {np.average(list(tprs_rf.values())):.3f} max: {max(tprs_rf.values()):.3f}')\n",
    "print(f'FPR min: {min(fprs_rf.values()):.3f} mean: {np.average(list(fprs_rf.values())):.3f} max: {max(fprs_rf.values()):.3f}')\n",
    "print(f'PPV min: {min(ppvs_rf.values()):.3f} mean: {np.average(list(ppvs_rf.values())):.3f} max: {max(ppvs_rf.values()):.3f}')\n",
    "print(f'ACC min: {min(accs_rf.values()):.3f} mean: {np.average(list(accs_rf.values())):.3f} max: {max(accs_rf.values()):.3f}')\n",
    "print(f'AUC min: {min(aucs_rf.values()):.3f} mean: {np.average(list(aucs_rf.values())):.3f} max: {max(aucs_rf.values()):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q5\n",
    "\n",
    "**Calculate the Cost of Fraud**\n",
    "\n",
    "- Recall that in Q3 and Q4, we saved the predictions of the testing set of fold #3 into the variables `y_hat_ab` and `y_hat_rf` for the AdaBoost and RandomForest models respectively.\n",
    "- We want to use these predictions to perform a cost analysis.\n",
    "    - Specifically, Mr. Bank Man wants to know how much money he is going to save if he deploys either of these fraud algorithms to his bank's real-time payment processing system.\n",
    "    - Assume that there is not a currently deployed fraud detection algorithm.\n",
    "- Our cost analysis model is defined as follows:\n",
    "    - For every fraudulent transaction that is not predicted as fraudulent, the bank loses **twice the transaction amount**.  \n",
    "        - *Example*: If a fradulent charge for â‚¬10 goes undectected, it costs the bank â‚¬20.  \n",
    "    - For every non-fradulent transaction that is predicted as fradulent, the bank loses a **flat fee of â‚¬3** due to costs from customer service support and re-marking the transaction.\n",
    "\n",
    "Using the 3rd fold test sample, calculate how much money Mr. Bank Man will save with each algorithm. Write a recommendation of which algorithm to deploy to production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without a fraud detecting algorithm, the fraudulent cases will cost the bank 11242.37 euros. With the Adaboost classifier, it will save the bank 2704.05 euros. The random forest classifier saves the bank 6879.99 euros. Since the random forest classifer save around 3 times the amount of the Adaboost classifier, Mr. Bank Man should implement a random forest classifier over an Adaboost classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current cost to the bank is â‚¬11242.37\n"
     ]
    }
   ],
   "source": [
    "# First, calculate the current cost to the bank with no fraud detection\n",
    "d_test = d_test_df_X[3].copy()\n",
    "d_test['Actual'] = d_test_s_y[3]\n",
    "d_test['Pred'] = y_hat_ab\n",
    "d_test = d_test.rename(columns={29: 'Amount'})\n",
    "idxs = d_test.index[d_test['Actual']==1].tolist()\n",
    "cost = d_test.iloc[idxs][\"Amount\"]\n",
    "\n",
    "current_cost = sum(cost)\n",
    "print(f'The current cost to the bank is â‚¬{current_cost:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the AdaBoost classifier, the bank's costs will be:\n",
      "  Undetected fraud: â‚¬8496.32\n",
      "  False fraud: â‚¬42.00\n",
      "\n",
      "The bank will save â‚¬2704.05 by deploying the AdaBoost algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Finally, compute the costs/savings to the bank if we deploy the AdaBoost classifier\n",
    "idxs_ab_nPred = d_test.index[(d_test['Actual']==1) & (d_test['Pred'] == 0)].tolist()\n",
    "cost_ab_nPred = d_test.iloc[idxs_ab_nPred][\"Amount\"]\n",
    "\n",
    "idxs_ab_nFraud = d_test.index[(d_test['Actual']==0) & (d_test['Pred'] == 1)].tolist()\n",
    "#cost_ab_nFraud = d_test.iloc[idxs_ab][\"Amount\"]\n",
    "\n",
    "cost_ab_undetected_fraud = sum(cost_ab_nPred*2)\n",
    "cost_ab_false_fraud = len(idxs_ab_nFraud) * 3\n",
    "savings_ab = current_cost - (cost_ab_undetected_fraud + cost_ab_false_fraud)\n",
    "#if(savings_ab > 0):\n",
    "#    savings_ab = cost_ab_undetected_fraud + cost_ab_false_fraud\n",
    "\n",
    "print('With the AdaBoost classifier, the bank\\'s costs will be:')\n",
    "print(f'  Undetected fraud: â‚¬{cost_ab_undetected_fraud:.2f}')\n",
    "print(f'  False fraud: â‚¬{cost_ab_false_fraud:.2f}')\n",
    "print()\n",
    "print(f'The bank will save â‚¬{savings_ab:.2f} by deploying the AdaBoost algorithm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the RandomForest classifier, the bank's costs will be:\n",
      "  Undetected fraud: â‚¬4356.38\n",
      "  False fraud: â‚¬6.00\n",
      "\n",
      "The bank will save â‚¬6879.99 by deploying the AdaBoost algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Finally, compute the costs/savings to the bank if we deploy the RandomForest classifier\n",
    "d_test = d_test_df_X[3].copy()\n",
    "d_test['Actual'] = d_test_s_y[3]\n",
    "d_test['Pred'] = y_hat_rf\n",
    "d_test = d_test.rename(columns={29: 'Amount'})\n",
    "\n",
    "idxs_rf_nPred = d_test.index[(d_test['Actual']==1) & (d_test['Pred'] == 0)].tolist()\n",
    "cost_rf_nPred = d_test.iloc[idxs_rf_nPred][\"Amount\"]\n",
    "\n",
    "idxs_rf_nFraud = d_test.index[(d_test['Actual']==0) & (d_test['Pred'] == 1)].tolist()\n",
    "\n",
    "cost_rf_undetected_fraud = sum(cost_rf_nPred*2)\n",
    "cost_rf_false_fraud = len(idxs_rf_nFraud)*3\n",
    "savings_rf = current_cost - (cost_rf_undetected_fraud + cost_rf_false_fraud)\n",
    "#if(savings_rf > 0):\n",
    "#    savings_rf = cost_rf_undetected_fraud + cost_rf_false_fraud\n",
    "\n",
    "print('With the RandomForest classifier, the bank\\'s costs will be:')\n",
    "print(f'  Undetected fraud: â‚¬{cost_rf_undetected_fraud:.2f}')\n",
    "print(f'  False fraud: â‚¬{cost_rf_false_fraud:.2f}')\n",
    "print()\n",
    "print(f'The bank will save â‚¬{savings_rf:.2f} by deploying the AdaBoost algorithm.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "329e_HW12",
   "tests": {
    "q1": {
     "name": "q1",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3computations": {
     "name": "q3computations",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4computations": {
     "name": "q4computations",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5computations": {
     "name": "q5computations",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
